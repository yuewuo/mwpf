//! Parallel Primal Module
//! 
//! A parallel implementation of the primal module, by calling functions provided by the serial primal module
//! 
//! 
#![cfg_attr(feature="unsafe_pointer", allow(dropping_references))]

// use color_print::cprintln;
use super::dual_module::*;
use crate::{dual_module_parallel::*, plugin};
use crate::dual_module_pq::{FutureQueueMethods, Obstacle};
use super::pointers::*;
use super::primal_module::*;
use super::primal_module_serial::*;
use super::util::*;
use std::cmp::Ordering;
use super::visualize::*;
use crate::rayon::prelude::*;
use serde::{Deserialize, Serialize};
use std::collections::{BTreeMap, BTreeSet};
use std::ops::DerefMut;
use std::sync::{Arc, Condvar, Mutex, Weak};
use std::time::{Duration, Instant};
use crate::num_traits::Zero;
use crate::plugin::*;
use crate::num_traits::FromPrimitive;

#[cfg(all(feature = "pointer", feature = "non-pq"))]
use crate::dual_module_serial::{EdgeWeak, VertexWeak, EdgePtr, VertexPtr};
#[cfg(all(feature = "pointer", not(feature = "non-pq")))]
use crate::dual_module_pq::{Edge, EdgeWeak, VertexWeak, EdgePtr, VertexPtr};


pub struct PrimalModuleParallel {
    /// the basic wrapped serial modules at the beginning, afterwards the fused units are appended after them
    pub units: Vec<PrimalModuleParallelUnitPtr>,
    /// local configuration
    pub config: PrimalModuleParallelConfig,
    /// partition information generated by the config
    pub partition_info: Arc<PartitionInfo>,
    /// thread pool used to execute async functions in parallel
    pub thread_pool: Arc<rayon::ThreadPool>,
    /// the time of calling [`PrimalModuleParallel::parallel_solve_step_callback`] method
    pub last_solve_start_time: ArcRwLock<Instant>,
}

pub struct PrimalModuleParallelUnit {
    /// the index
    pub unit_index: usize,
    /// the dual module interface, for constant-time clear
    pub interface_ptr: DualModuleInterfacePtr,
    /// partition information generated by the config
    pub partition_info: Arc<PartitionInfo>,
    /// the owned serial primal module
    pub serial_module: PrimalModuleSerial,
    /// adjacent parallel units of this unit, and whether they each are fused with this unit
    pub adjacent_parallel_units: BTreeMap<PrimalModuleParallelUnitWeak, bool>,
    /// whether this unit is solved 
    pub is_solved: bool,
    /// record the time of events
    pub event_time: Option<PrimalModuleParallelUnitEventTime>,
}


pub type PrimalModuleParallelUnitPtr = ArcManualSafeLock<PrimalModuleParallelUnit>;
pub type PrimalModuleParallelUnitWeak = WeakManualSafeLock<PrimalModuleParallelUnit>;

impl std::fmt::Debug for PrimalModuleParallelUnitPtr {
    fn fmt(&self, f: &mut std::fmt::Formatter) -> std::fmt::Result {
        let unit = self.read_recursive();
        write!(f, "{}", unit.unit_index)
    }
}

impl std::fmt::Debug for PrimalModuleParallelUnitWeak {
    fn fmt(&self, f: &mut std::fmt::Formatter) -> std::fmt::Result {
        self.upgrade_force().fmt(f)
    }
}

impl Ord for PrimalModuleParallelUnitPtr {
    fn cmp(&self, other: &Self) -> Ordering {
        // compare the pointer address 
        let ptr1 = Arc::as_ptr(self.ptr());
        let ptr2 = Arc::as_ptr(other.ptr());
        // https://doc.rust-lang.org/reference/types/pointer.html
        // "When comparing raw pointers they are compared by their address, rather than by what they point to."
        ptr1.cmp(&ptr2)
    }
}

impl PartialOrd for PrimalModuleParallelUnitPtr {
    fn partial_cmp(&self, other: &Self) -> Option<Ordering> {
        Some(self.cmp(other))
    }
}


impl Ord for PrimalModuleParallelUnitWeak {
    fn cmp(&self, other: &Self) -> Ordering {
        // compare the pointer address 
        let ptr1 = Weak::as_ptr(self.ptr());
        let ptr2 = Weak::as_ptr(other.ptr());
        // https://doc.rust-lang.org/reference/types/pointer.html
        // "When comparing raw pointers they are compared by their address, rather than by what they point to."
        ptr1.cmp(&ptr2)
    }
}

impl PartialOrd for PrimalModuleParallelUnitWeak {
    fn partial_cmp(&self, other: &Self) -> Option<Ordering> {
        Some(self.cmp(other))
    }
}

/// the time of critical events, for profiling purposes
#[derive(Debug, Clone, Serialize)]
pub struct PrimalModuleParallelUnitEventTime {
    /// unit starts executing
    pub start: f64,
    /// unit ends executing
    pub end: f64,
    /// thread index
    pub thread_index: usize,
}

impl Default for PrimalModuleParallelUnitEventTime {
    fn default() -> Self {
        Self::new()
    }
}

impl PrimalModuleParallelUnitEventTime {
    pub fn new() -> Self {
        Self {
            start: 0.,
            end: 0.,
            thread_index: rayon::current_thread_index().unwrap_or(0),
        }
    }
}

#[derive(Debug, Clone, Serialize, Deserialize)]
#[serde(deny_unknown_fields)]
pub struct PrimalModuleParallelConfig {
    /// enable async execution of dual operations; only used when calling top-level operations, not used in individual units
    #[serde(default = "primal_module_parallel_default_configs::thread_pool_size")]
    pub thread_pool_size: usize,
    /// pin threads to cores sequentially
    #[serde(default = "primal_module_parallel_default_configs::pin_threads_to_cores")]
    pub pin_threads_to_cores: bool,
    /// timeout for each unit solving process
    #[serde(default = "primal_module_parallel_default_configs::timeout")]
    pub timeout: f64,
}

impl Default for PrimalModuleParallelConfig {
    fn default() -> Self {
        serde_json::from_value(json!({})).unwrap()
    }
}

pub mod primal_module_parallel_default_configs {
    pub fn thread_pool_size() -> usize {
        0
    } // by default to the number of CPU cores
      // pub fn thread_pool_size() -> usize { 1 }  // debug: use a single core
    pub fn pin_threads_to_cores() -> bool {
        false
    } // pin threads to cores to achieve most stable results
    pub fn timeout() -> f64 {
        (10 * 60) as f64
    }
}

impl PrimalModuleParallel {
    pub fn new_config(
        initializer: &SolverInitializer,
        partition_info: &PartitionInfo,
        config: PrimalModuleParallelConfig,
        growing_strategy: GrowingStrategy,
        plugins: Arc<PluginVec>,
    ) -> Self {
        let partition_info = Arc::new(partition_info.clone());
        let mut thread_pool_builder = rayon::ThreadPoolBuilder::new();
        if config.thread_pool_size != 0 {
            thread_pool_builder = thread_pool_builder.num_threads(config.thread_pool_size);
        }
        if config.pin_threads_to_cores {
            let core_ids = core_affinity::get_core_ids().unwrap();
            // println!("core_ids: {core_ids:?}");
            thread_pool_builder = thread_pool_builder.start_handler(move |thread_index| {
                // https://stackoverflow.com/questions/7274585/linux-find-out-hyper-threaded-core-id
                if thread_index < core_ids.len() {
                    crate::core_affinity::set_for_current(core_ids[thread_index]);
                } // otherwise let OS decide which core to execute
            });
        }

        let thread_pool = thread_pool_builder.build().expect("creating thread pool failed");
        let mut units = vec![];
        let unit_count = partition_info.units.len();
        thread_pool.scope(|_| {
            (0..unit_count)
                .into_par_iter()
                .map(|unit_index| {
                    // println!("unit_index: {unit_index}");
                    let mut primal_module = PrimalModuleSerial::new_empty(initializer);
                    primal_module.growing_strategy = growing_strategy;
                    primal_module.plugins = plugins.clone();
                    primal_module.config = PrimalModuleSerialConfig{ timeout: config.timeout};
                    let interface_ptr = DualModuleInterfacePtr::new();

                    PrimalModuleParallelUnitPtr::new_value(PrimalModuleParallelUnit {
                        unit_index,
                        interface_ptr, 
                        partition_info: partition_info.clone(),
                        serial_module: primal_module,
                        adjacent_parallel_units: BTreeMap::new(),
                        is_solved: false,
                        event_time: None,
                    })
                })
                .collect_into_vec(&mut units);
        });

        // we need to fill in the BTreeMap of adjacent_parallel_units
        // we need to fill in the adjacent_parallel_units here 
        for unit_index in 0..partition_info.units.len() {
            // println!("for unit {:?}", unit_index);
            let mut unit = units[unit_index].write();
            for adjacent_unit_index in &partition_info.units[unit_index].adjacent_parallel_units {
                // println!("adjacent_parallel_unit: {:?}", adjacent_unit_index);
                let adjacnet_unit_pointer = &units[*adjacent_unit_index];
                unit.adjacent_parallel_units.insert(adjacnet_unit_pointer.downgrade(), false); 
                // println!("adjacent_parallel_unit ptr: {:?}", Arc::as_ptr(pointer.clone().ptr()));
            }
            drop(unit);
        }

        Self {
            units,
            config,
            partition_info,
            thread_pool: Arc::new(thread_pool),
            last_solve_start_time: ArcRwLock::new_value(Instant::now()),
        }
    }
}

impl PrimalModuleParallelUnitPtr {

    // syndrome pattern is created in this function. This function could not be used for dynamic fusion
    fn individual_solve<DualSerialModule: DualModuleImpl + Send + Sync, Queue, F: Send + Sync>(
        &self,
        primal_module_parallel: &PrimalModuleParallel,
        partitioned_syndrome_pattern: PartitionedSyndromePattern,
        parallel_dual_module: &DualModuleParallel<DualSerialModule, Queue>,
        callback: &mut Option<&mut F>,
    ) where
        F: FnMut(
            &DualModuleInterfacePtr,
            &DualModuleParallelUnit<DualSerialModule, Queue>,
            &PrimalModuleSerial,
            Option<&GroupMaxUpdateLength>,
        ),
        Queue: FutureQueueMethods<Rational, Obstacle> + Default + std::fmt::Debug + Send + Sync + Clone,
    {
        let mut event_time = PrimalModuleParallelUnitEventTime::new();
        event_time.start = primal_module_parallel
            .last_solve_start_time
            .read_recursive()
            .elapsed()
            .as_secs_f64();

        let mut primal_unit = self.write();
        let unit_index = primal_unit.unit_index;
        // cprintln!("<green>individual_solve for unit: {:?}</green>", unit_index);
        // println!("unit index: {}", primal_unit.unit_index);
        let dual_module_ptr = &parallel_dual_module.units[unit_index];
        // let mut dual_unit = dual_module_ptr.write();
        let partition_unit_info = &primal_unit.partition_info.units[unit_index];
        let owned_defect_range = partitioned_syndrome_pattern.partition(partition_unit_info);
        let interface_ptr = primal_unit.interface_ptr.clone();

       // solve the individual unit first 
       if !primal_unit.is_solved {
            // we solve the individual unit first
            let syndrome_pattern = Arc::new(owned_defect_range.expand());
            // let syndrome_pattern = Arc::new(SyndromePattern::new(dual_module_ptr.read_recursive().serial_module.all_defect_vertices.clone(), vec![]));
            // println!("defect vertices in unit: {:?} are {:?}", unit_index, syndrome_pattern.defect_vertices);
            primal_unit.serial_module.solve_step_callback_ptr(
                &interface_ptr,
                syndrome_pattern,
                &mut dual_module_ptr.clone(),
                |interface, dual_module, primal_module, group_max_update_length| {
                    if let Some(callback) = callback.as_mut() {
                        callback(interface, dual_module, primal_module, Some(group_max_update_length));
                    }
                },
            );
            primal_unit.is_solved = true;
            // println!("unit: {:?}, is_solved: {:?}", unit_index, primal_unit.is_solved);
            if let Some(callback) = callback.as_mut() {
                callback(&primal_unit.interface_ptr, &dual_module_ptr.write().deref_mut(), &primal_unit.serial_module, None);
            }
        }
        event_time.end = primal_module_parallel
            .last_solve_start_time
            .read_recursive()
            .elapsed()
            .as_secs_f64();
        primal_unit.event_time = Some(event_time);
        drop(primal_unit);
    }

    /// call this only if children is guaranteed to be ready and solved
    #[allow(clippy::unnecessary_cast)]
    fn fuse_and_solve<DualSerialModule: DualModuleImpl + Send + Sync, Queue, F: Send + Sync>(
        &self,
        primal_module_parallel: &PrimalModuleParallel,
        partitioned_syndrome_pattern: PartitionedSyndromePattern,
        parallel_dual_module: &DualModuleParallel<DualSerialModule, Queue>,
        callback: &mut Option<&mut F>,
    ) where
        F: FnMut(
            &DualModuleInterfacePtr,
            &DualModuleParallelUnit<DualSerialModule, Queue>,
            &PrimalModuleSerial,
            Option<&GroupMaxUpdateLength>,
        ),
        Queue: FutureQueueMethods<Rational, Obstacle> + Default + std::fmt::Debug + Send + Sync + Clone,
    {
        // cprintln!("<green>fuse_and_solve for unit: {:?}</green>", self.read_recursive().unit_index);
        // assert!(self.read_recursive().is_solved, "this unit must have been solved before we fuse it with its neighbors");
        let mut event_time = PrimalModuleParallelUnitEventTime::new();
        event_time.start = primal_module_parallel
            .last_solve_start_time
            .read_recursive()
            .elapsed()
            .as_secs_f64();
        
        // this unit has been solved, we can fuse it with its adjacent units
        // we iterate through the dag_partition_unit to fuse units together 
        let self_dual_ptr = &parallel_dual_module.units[self.read_recursive().unit_index];
        self.fuse_operation_on_adjacent_units(self_dual_ptr, parallel_dual_module);

        let mut primal_unit = self.write();
        primal_unit.fuse_operation_on_self(self_dual_ptr, parallel_dual_module);

        primal_unit.combine_all_mirrored_vertices_first_time(self_dual_ptr);

        // primal_unit.seperate_all_mirrored_vertices(self_dual_ptr);
        // primal_unit.combine_all_mirrored_vertices_again(self_dual_ptr);

        if let Some(callback) = callback.as_mut() {
            callback(&primal_unit.interface_ptr, &self_dual_ptr.write().deref_mut(), &primal_unit.serial_module, None);
        }

        // now we have finished fusing self with all adjacent units, we run solve again

        // let mut dual_unit = self_dual_ptr.write();
        let partition_unit_info = &primal_unit.partition_info.units[primal_unit.unit_index];
        let owned_defect_range = partitioned_syndrome_pattern.partition(partition_unit_info);
        let interface_ptr = primal_unit.interface_ptr.clone();

        if primal_unit.is_solved {
            primal_unit.serial_module.solve_step_callback_interface_loaded_ptr(
                &interface_ptr,
                &mut self_dual_ptr.clone(),
                |interface, dual_module, primal_module, group_max_update_length| {
                    if let Some(callback) = callback.as_mut() {
                        callback(interface, dual_module, primal_module, Some(group_max_update_length));
                    }
                },
            );
            if let Some(callback) = callback.as_mut() {
                callback(&primal_unit.interface_ptr, &self_dual_ptr.write().deref_mut(), &primal_unit.serial_module, None);
            }
        } else {
            // we solve the individual unit first
            let syndrome_pattern = Arc::new(owned_defect_range.expand());
            // println!("unit: {:?}, owned_defect_range: {:?}", primal_unit.unit_index, syndrome_pattern);
            primal_unit.serial_module.solve_step_callback_ptr(
                &interface_ptr,
                syndrome_pattern,
                &mut self_dual_ptr.clone(),
                |interface, dual_module, primal_module, group_max_update_length| {
                    if let Some(callback) = callback.as_mut() {
                        callback(interface, dual_module, primal_module, Some(group_max_update_length));
                    }
                },
            );
            primal_unit.is_solved = true;
            if let Some(callback) = callback.as_mut() {
                callback(&primal_unit.interface_ptr, &self_dual_ptr.write().deref_mut(), &primal_unit.serial_module, None);
            }
        }

        event_time.end = primal_module_parallel
            .last_solve_start_time
            .read_recursive()
            .elapsed()
            .as_secs_f64();
        primal_unit.event_time = Some(event_time);
    }

    fn fuse_operation_on_adjacent_units<DualSerialModule: DualModuleImpl + Send + Sync, Queue>
    (&self, 
    self_dual_ptr: &DualModuleParallelUnitPtr<DualSerialModule, Queue>,
    parallel_dual_module: &DualModuleParallel<DualSerialModule, Queue>,
    ) 
    where Queue: FutureQueueMethods<Rational, Obstacle> + Default + std::fmt::Debug + Send + Sync + Clone,
    {
        // we need to fuse this unit with all of its adjacent units
        // this is for the adjacent unit
        for (adjacent_unit_weak, is_fused) in self.read_recursive().adjacent_parallel_units.iter() {
            if *is_fused {
                // if already fused, then skip
                continue;
            } else {
                let adjacent_unit_ptr = adjacent_unit_weak.upgrade_force();
                let mut adjacent_unit = adjacent_unit_ptr.write();
                if let Some(is_fused_with_self) = adjacent_unit.adjacent_parallel_units.get_mut(&self.downgrade()) {
                    *is_fused_with_self = true;
                } else {
                    panic!("this adjacent unit does not have self as its adjacent unit, check new_config");
                }

                // after setting the bool in BTreeMap of PrimalModuleParallelUnit, we need to add the corresponding DualModuleParallelUnit 
                let adjacent_dual_unit_ptr = &parallel_dual_module.units[adjacent_unit.unit_index];
                let mut adjacent_dual_unit = adjacent_dual_unit_ptr.write();
                adjacent_dual_unit.adjacent_parallel_units.push(self_dual_ptr.downgrade());
                drop(adjacent_unit);
            }

        }

    }

    pub fn seperate_parallel_solve<DualSerialModule: DualModuleImpl + Send + Sync, Queue>(
        &mut self,
        syndrome_pattern: Arc<SyndromePattern>,
        seperate_dual_module: &mut DualModuleParallelUnit<DualSerialModule, Queue>,
        parallel_primal_module: &PrimalModuleParallel,
        parallel_dual_module: &DualModuleParallel<DualSerialModule, Queue>,
        seperate_partition_info: &PartitionInfo,
        no_per_layer: usize,
    ) where Queue: FutureQueueMethods<Rational, Obstacle> + Default + std::fmt::Debug + Send + Sync + Clone,
    {
        self.seperate_parallel_solve_step_callback(syndrome_pattern, seperate_dual_module, parallel_primal_module, parallel_dual_module, seperate_partition_info, no_per_layer, |_, _, _, _| {});
    }

    pub fn seperate_parallel_solve_visualizer<DualSerialModule: DualModuleImpl + Send + Sync + MWPSVisualizer, Queue>(
        &mut self,
        syndrome_pattern: Arc<SyndromePattern>,
        seperate_dual_module: &mut DualModuleParallelUnit<DualSerialModule, Queue>,
        parallel_primal_module: &PrimalModuleParallel,
        parallel_dual_module: &DualModuleParallel<DualSerialModule, Queue>,
        seperate_partition_info: &PartitionInfo,
        no_per_layer: usize,
        visualizer: Option<&mut Visualizer>,
    ) where Queue: FutureQueueMethods<Rational, Obstacle> + Default + std::fmt::Debug + Send + Sync + Clone,
    {
        if let Some(visualizer) = visualizer {
            self.seperate_parallel_solve_step_callback(
                syndrome_pattern,
                seperate_dual_module,
                parallel_primal_module,
                parallel_dual_module,
                seperate_partition_info,
                no_per_layer,
                |interface, dual_module, primal_module, group_max_update_length| {
                    if let Some(group_max_update_length) = group_max_update_length {
                        if cfg!(debug_assertions) {
                            // println!("group_max_update_length: {:?}", group_max_update_length);
                        }
                        if group_max_update_length.is_unbounded() {
                            visualizer
                                .snapshot_combined("unbounded grow".to_string(), vec![interface, dual_module, primal_module])
                                .unwrap();
                        } else if let Some(length) = group_max_update_length.get_valid_growth() {
                            visualizer
                                .snapshot_combined(format!("grow {length}"), vec![interface, dual_module, primal_module])
                                .unwrap();
                        } else {
                            let first_conflict = format!("{:?}", group_max_update_length.peek().unwrap());
                            visualizer
                                .snapshot_combined(
                                    format!("resolve {first_conflict}"),
                                    vec![interface, dual_module, primal_module],
                                )
                                .unwrap();
                        };
                    } else {
                        visualizer
                            .snapshot_combined("unit solved".to_string(), vec![interface, dual_module, primal_module])
                            .unwrap();
                    }
                    
                },
            );
            // let last_unit = self.units.last().unwrap().read_recursive();
            // visualizer
            //     .snapshot_combined(
            //         "solved".to_string(),
            //         vec![&last_unit.interface_ptr, parallel_dual_module, self],
            //     )
            //     .unwrap();
        } else {
            self.seperate_parallel_solve(syndrome_pattern, seperate_dual_module, parallel_primal_module, parallel_dual_module, seperate_partition_info, no_per_layer);
        }
    }

    pub fn seperate_parallel_solve_step_callback<DualSerialModule: DualModuleImpl + Send + Sync, Queue, F: Send + Sync>(
        &mut self,
        syndrome_pattern: Arc<SyndromePattern>,
        seperate_dual_module: &mut DualModuleParallelUnit<DualSerialModule, Queue>,
        parallel_primal_module: &PrimalModuleParallel,
        parallel_dual_module: &DualModuleParallel<DualSerialModule, Queue>,
        seperate_partition_info: &PartitionInfo,
        no_per_layer: usize,
        mut callback: F,
    ) where
        F: FnMut(
            &DualModuleInterfacePtr,
            &DualModuleParallelUnit<DualSerialModule, Queue>,
            &PrimalModuleSerial,
            Option<&GroupMaxUpdateLength>,
        ),
        Queue: FutureQueueMethods<Rational, Obstacle> + Default + std::fmt::Debug + Send + Sync + Clone,
    {
        // sequential implementation
        self.seperate_individual_solve::<DualSerialModule, Queue, F>(
            PartitionedSyndromePattern::new(&syndrome_pattern), 
            seperate_dual_module, 
            &mut Some(&mut callback),
        );

        self.solve_additional_unit(seperate_dual_module, parallel_primal_module, parallel_dual_module, seperate_partition_info, no_per_layer, &mut Some(&mut callback));
    }

    pub fn fuse_additional_unit<DualSerialModule: DualModuleImpl + Send + Sync, Queue, F: Send + Sync>(
        &mut self,
        seperate_dual_module: &mut DualModuleParallelUnit<DualSerialModule, Queue>,
        parallel_primal_module: &PrimalModuleParallel,
        parallel_dual_module: &DualModuleParallel<DualSerialModule, Queue>,
        seperate_partition_info: &PartitionInfo,
        no_per_layer: usize,
        mut callback: &mut Option<&mut F>,
    ) where
        F: FnMut(
            &DualModuleInterfacePtr,
            &DualModuleParallelUnit<DualSerialModule, Queue>,
            &PrimalModuleSerial,
            Option<&GroupMaxUpdateLength>,
        ),
        Queue: FutureQueueMethods<Rational, Obstacle> + Default + std::fmt::Debug + Send + Sync + Clone,
    {
        // we connect the boundary vertices in the newly added unit with the original unit by adding/creating edges 
        let unit_index_original = seperate_partition_info.config.fusions[0].1;
        let dual_unit_original = &parallel_dual_module.units[unit_index_original];
        let vertices_to_be_fused_original = seperate_partition_info.config.partitions[0];
        let vertices_to_be_fused_new = seperate_partition_info.units[0].boundary_vertices[0];
    
        for vertex_index in vertices_to_be_fused_new.start()..vertices_to_be_fused_new.end() {
            let new_vertex_ptr = &seperate_dual_module.serial_module.vertices[vertex_index];
            let mut new_vertex = new_vertex_ptr.write();

            for edge_weak in new_vertex.edges.iter() {
                let edge_ptr = edge_weak.upgrade_force();
                let edge = edge_ptr.read_recursive();
                let before_mirror_vertices = &edge.vertices;
                let mut after_mirror_vertices: Vec<VertexWeak> = before_mirror_vertices.iter().map(|v_weak| {
                    let v_ptr = v_weak.upgrade_force();
                    let v = v_ptr.read_recursive();
                    if v.vertex_index > no_per_layer {
                        let local_index = v.vertex_index - no_per_layer;
                        let actual_local_index = dual_unit_original.read_recursive().owning_range.len() - no_per_layer + local_index;
                        let corresponding_vertex_original = &dual_unit_original.read_recursive().serial_module.vertices[actual_local_index];
                        corresponding_vertex_original.downgrade()
                    } else {
                        v_weak.clone()
                    }
                }).collect::<Vec<_>>();
                
                let new_edge_ptr = EdgePtr::new_value(Edge {
                    edge_index: 0, // should not matter
                    weight: edge.weight,
                    dual_nodes: vec![],
                    vertices: after_mirror_vertices, // we need to fill this in now
                    last_updated_time: Rational::zero(),
                    growth_at_last_updated_time: Rational::zero(),
                    grow_rate: Rational::zero(),
                    unit_index: Some(3), // should not matter
                    connected_to_boundary_vertex: true,
                    #[cfg(feature = "incr_lp")]
                    cluster_weights: hashbrown::HashMap::new(),
                });
                seperate_dual_module.serial_module.edges.push(new_edge_ptr);
            }
        }
    }

    pub fn solve_additional_unit<DualSerialModule: DualModuleImpl + Send + Sync, Queue, F: Send + Sync>(
        &mut self,
        seperate_dual_module: &mut DualModuleParallelUnit<DualSerialModule, Queue>,
        parallel_primal_module: &PrimalModuleParallel,
        parallel_dual_module: &DualModuleParallel<DualSerialModule, Queue>,
        seperate_partition_info: &PartitionInfo,
        no_per_layer: usize,
        mut callback: &mut Option<&mut F>,
    ) where
        F: FnMut(
            &DualModuleInterfacePtr,
            &DualModuleParallelUnit<DualSerialModule, Queue>,
            &PrimalModuleSerial,
            Option<&GroupMaxUpdateLength>,
        ),
        Queue: FutureQueueMethods<Rational, Obstacle> + Default + std::fmt::Debug + Send + Sync + Clone,
    {
        // we need to fuse this newly added unit with the original unit blocks 
        self.fuse_additional_unit(seperate_dual_module, parallel_primal_module, parallel_dual_module, seperate_partition_info, no_per_layer, callback);

        // then, we call bfs grow and solve on the newly added unit again
        // let mut dual_unit = self_dual_ptr.write();
        // let partition_unit_info = &primal_unit.partition_info.units[primal_unit.unit_index];
        // let owned_defect_range = partitioned_syndrome_pattern.partition(partition_unit_info);
        let interface_ptr = self.interface_ptr.clone();
        let primal_unit = self.write();

        primal_unit.serial_module.solve_step_callback_interface_loaded(
            &interface_ptr,
            seperate_dual_module,
            |interface, dual_module, primal_module, group_max_update_length| {
                if let Some(callback) = callback.as_mut() {
                    callback(interface, dual_module, primal_module, Some(group_max_update_length));
                }
            },
        );
        if let Some(callback) = callback.as_mut() {
            callback(&interface_ptr, &seperate_dual_module, &primal_unit.serial_module, None);
        }
    }



    // syndrome pattern is created in this function. This function could not be used for dynamic fusion
    fn seperate_individual_solve<DualSerialModule: DualModuleImpl + Send + Sync, Queue, F: Send + Sync>(
        &mut self,
        partitioned_syndrome_pattern: PartitionedSyndromePattern,
        seperate_dual_module: &DualModuleParallelUnit<DualSerialModule, Queue>,
        callback: &mut Option<&mut F>,
    ) where
        F: FnMut(
            &DualModuleInterfacePtr,
            &DualModuleParallelUnit<DualSerialModule, Queue>,
            &PrimalModuleSerial,
            Option<&GroupMaxUpdateLength>,
        ),
        Queue: FutureQueueMethods<Rational, Obstacle> + Default + std::fmt::Debug + Send + Sync + Clone,
    {
        let mut primal_unit = self.write();
        let unit_index = primal_unit.unit_index;
        let partition_unit_info = &primal_unit.partition_info.units[0];
        let owned_defect_range = partitioned_syndrome_pattern.partition(partition_unit_info);
        let interface_ptr = &primal_unit.interface_ptr;

       // solve the individual unit first 
       if !primal_unit.is_solved {
            // we solve the individual unit first
            let syndrome_pattern = Arc::new(owned_defect_range.expand());
            primal_unit.serial_module.solve_step_callback(
                &interface_ptr,
                syndrome_pattern,
                &mut seperate_dual_module.clone(),
                |interface, dual_module, primal_module, group_max_update_length| {
                    if let Some(callback) = callback.as_mut() {
                        callback(interface, dual_module, primal_module, Some(group_max_update_length));
                    }
                },
            );
            primal_unit.is_solved = true;
            // println!("unit: {:?}, is_solved: {:?}", unit_index, primal_unit.is_solved);
            if let Some(callback) = callback.as_mut() {
                callback(&primal_unit.interface_ptr, &seperate_dual_module, &primal_unit.serial_module, None);
            }
        }
       
        drop(primal_unit);
    }

}

impl PrimalModuleParallelUnit {
    // we need this to create primal_module for the newly (additionally) added unit
    pub fn new_config(
        initializer: &SolverInitializer,
        partition_info: &PartitionInfo,
        config: PrimalModuleParallelConfig,
        growing_strategy: GrowingStrategy,
        plugins: Arc<PluginVec>,
    ) -> Self {
        let partition_info = Arc::new(partition_info.clone());
        // let mut thread_pool_builder = rayon::ThreadPoolBuilder::new();
        // if config.thread_pool_size != 0 {
        //     thread_pool_builder = thread_pool_builder.num_threads(config.thread_pool_size);
        // }
        // if config.pin_threads_to_cores {
        //     let core_ids = core_affinity::get_core_ids().unwrap();
        //     // println!("core_ids: {core_ids:?}");
        //     thread_pool_builder = thread_pool_builder.start_handler(move |thread_index| {
        //         // https://stackoverflow.com/questions/7274585/linux-find-out-hyper-threaded-core-id
        //         if thread_index < core_ids.len() {
        //             crate::core_affinity::set_for_current(core_ids[thread_index]);
        //         } // otherwise let OS decide which core to execute
        //     });
        // }

        // let thread_pool = thread_pool_builder.build().expect("creating thread pool failed");
        let mut primal_module = PrimalModuleSerial::new_empty(initializer);
        primal_module.growing_strategy = growing_strategy;
        primal_module.plugins = plugins.clone();
        primal_module.config = PrimalModuleSerialConfig{ timeout: config.timeout};
        let interface_ptr = DualModuleInterfacePtr::new();

        PrimalModuleParallelUnit {
            unit_index: partition_info.units[0].unit_index,
            interface_ptr, 
            partition_info: partition_info.clone(),
            serial_module: primal_module,
            adjacent_parallel_units: BTreeMap::new(), // to be initalized/filled in later
            is_solved: false,
            event_time: None,
        }
    }

    fn combine_all_mirrored_vertices_first_time<DualSerialModule: DualModuleImpl + Send + Sync, Queue>
    (&mut self, 
    self_dual_ptr: &DualModuleParallelUnitPtr<DualSerialModule, Queue>,
    ) 
        where Queue: FutureQueueMethods<Rational, Obstacle> + Default + std::fmt::Debug + Send + Sync + Clone,
    {
        let self_dual_unit = self_dual_ptr.read_recursive();

        // we need to add the edges connected to mirrored vertices in non-boundary unit to the vertices in boundary unit 
        for i in 0..self_dual_unit.serial_module.vertices.len() {
            let vertex = &self_dual_unit.serial_module.vertices[i];
            let mut edges_to_add = Vec::new();
            for corresponding_mirrored_vertex in vertex.read_recursive().mirrored_vertices.iter() {

                for edge_weak in corresponding_mirrored_vertex.upgrade_force().read_recursive().edges.iter() {
                    let edge_ptr = edge_weak.upgrade_force();
                    let mut edge = edge_ptr.write();
                    for local_vertex in edge.vertices.iter_mut() {
                        if local_vertex.eq(&corresponding_mirrored_vertex) {
                            *local_vertex = vertex.downgrade();
                        }
                    }
                }
                edges_to_add.extend(corresponding_mirrored_vertex.upgrade_force().read_recursive().edges.clone());
            }
            vertex.write().edges.extend(edges_to_add);
        }
    }

    fn combine_all_mirrored_vertices_again<DualSerialModule: DualModuleImpl + Send + Sync, Queue>
    (&mut self, 
    self_dual_ptr: &DualModuleParallelUnitPtr<DualSerialModule, Queue>,
    ) 
        where Queue: FutureQueueMethods<Rational, Obstacle> + Default + std::fmt::Debug + Send + Sync + Clone,
    {
        let self_dual_unit = self_dual_ptr.read_recursive();

        // we need to add the edges connected to mirrored vertices in non-boundary unit to the vertices in boundary unit 
        for i in 0..self_dual_unit.serial_module.vertices.len() {
            let vertex = &self_dual_unit.serial_module.vertices[i];
            // let mut edges_to_add = Vec::new();
            for corresponding_mirrored_vertex in vertex.read_recursive().mirrored_vertices.iter() {

                for edge_weak in corresponding_mirrored_vertex.upgrade_force().read_recursive().edges.iter() {
                    let edge_ptr = edge_weak.upgrade_force();
                    let mut edge = edge_ptr.write();
                    for local_vertex in edge.vertices.iter_mut() {
                        if local_vertex.eq(&corresponding_mirrored_vertex) {
                            *local_vertex = vertex.downgrade();
                        }
                    }
                }
            }
        }
    }

    // change the edges in the non-boundary units to connect to mirrored vertices (instead of vertices in boundary unit) again
    fn seperate_all_mirrored_vertices<DualSerialModule: DualModuleImpl + Send + Sync, Queue>
    (&mut self, 
    self_dual_ptr: &DualModuleParallelUnitPtr<DualSerialModule, Queue>,
    ) 
        where Queue: FutureQueueMethods<Rational, Obstacle> + Default + std::fmt::Debug + Send + Sync + Clone,
    {
        let self_dual_unit = self_dual_ptr.read_recursive();

        // we need to add the edges connected to mirrored vertices in non-boundary unit to the vertices in boundary unit 
        for i in 0..self_dual_unit.serial_module.vertices.len() {
            let vertex = &self_dual_unit.serial_module.vertices[i];
            // let mut edges_to_add = Vec::new();
            for corresponding_mirrored_vertex in vertex.read_recursive().mirrored_vertices.iter() {

                for edge_weak in corresponding_mirrored_vertex.upgrade_force().read_recursive().edges.iter() {
                    let edge_ptr = edge_weak.upgrade_force();
                    let mut edge = edge_ptr.write();
                    for local_vertex in edge.vertices.iter_mut() {
                        if *local_vertex == vertex.downgrade() {
                            *local_vertex = corresponding_mirrored_vertex.clone();
                        }
                    }
                }
            }
        }
    }

    fn fuse_operation_on_self<DualSerialModule: DualModuleImpl + Send + Sync, Queue>
    (&mut self,
    self_dual_ptr: &DualModuleParallelUnitPtr<DualSerialModule, Queue>,
    parallel_dual_module: &DualModuleParallel<DualSerialModule, Queue>,
    ) 
    where Queue: FutureQueueMethods<Rational, Obstacle> + Default + std::fmt::Debug + Send + Sync + Clone,
    {
        let mut self_dual_unit = self_dual_ptr.write();
        for (adjacent_unit_ptr, is_fused) in self.adjacent_parallel_units.iter_mut() {
            if *is_fused {
                // if already fused, then skip
                continue;
            } else {
                *is_fused = true;

                // we need to add the DualModuleParallelUnitPtr to the adjacent_parallel_units of self
                let adjacent_dual_unit_ptr = &parallel_dual_module.units[adjacent_unit_ptr.upgrade_force().read_recursive().unit_index];
                self_dual_unit.adjacent_parallel_units.push(adjacent_dual_unit_ptr.downgrade());
            }
        }
        drop(self_dual_unit);
    }
}

impl PrimalModuleParallel {
    pub fn parallel_solve<DualSerialModule: DualModuleImpl + Send + Sync, Queue>(
        &mut self,
        syndrome_pattern: Arc<SyndromePattern>,
        parallel_dual_module: &DualModuleParallel<DualSerialModule, Queue>,
    ) where Queue: FutureQueueMethods<Rational, Obstacle> + Default + std::fmt::Debug + Send + Sync + Clone,
    {
        self.parallel_solve_step_callback(syndrome_pattern, parallel_dual_module, |_, _, _, _| {});
    }

    pub fn parallel_solve_visualizer<DualSerialModule: DualModuleImpl + Send + Sync + MWPSVisualizer, Queue>(
        &mut self,
        syndrome_pattern: Arc<SyndromePattern>,
        parallel_dual_module: &DualModuleParallel<DualSerialModule, Queue>,
        visualizer: Option<&mut Visualizer>,
    ) where Queue: FutureQueueMethods<Rational, Obstacle> + Default + std::fmt::Debug + Send + Sync + Clone,
    {
        if let Some(visualizer) = visualizer {
            self.parallel_solve_step_callback(
                syndrome_pattern,
                parallel_dual_module,
                |interface, dual_module, primal_module, group_max_update_length| {
                    if let Some(group_max_update_length) = group_max_update_length {
                        if cfg!(debug_assertions) {
                            // println!("group_max_update_length: {:?}", group_max_update_length);
                        }
                        if group_max_update_length.is_unbounded() {
                            visualizer
                                .snapshot_combined("unbounded grow".to_string(), vec![interface, dual_module, primal_module])
                                .unwrap();
                        } else if let Some(length) = group_max_update_length.get_valid_growth() {
                            visualizer
                                .snapshot_combined(format!("grow {length}"), vec![interface, dual_module, primal_module])
                                .unwrap();
                        } else {
                            let first_conflict = format!("{:?}", group_max_update_length.peek().unwrap());
                            visualizer
                                .snapshot_combined(
                                    format!("resolve {first_conflict}"),
                                    vec![interface, dual_module, primal_module],
                                )
                                .unwrap();
                        };
                    } else {
                        visualizer
                            .snapshot_combined("unit solved".to_string(), vec![interface, dual_module, primal_module])
                            .unwrap();
                    }
                    
                },
            );
            // let last_unit = self.units.last().unwrap().read_recursive();
            // visualizer
            //     .snapshot_combined(
            //         "solved".to_string(),
            //         vec![&last_unit.interface_ptr, parallel_dual_module, self],
            //     )
            //     .unwrap();
        } else {
            self.parallel_solve(syndrome_pattern, parallel_dual_module);
        }
    }

    pub fn parallel_solve_step_callback<DualSerialModule: DualModuleImpl + Send + Sync, Queue, F: Send + Sync>(
        &mut self,
        syndrome_pattern: Arc<SyndromePattern>,
        parallel_dual_module: &DualModuleParallel<DualSerialModule, Queue>,
        mut callback: F,
    ) where
        F: FnMut(
            &DualModuleInterfacePtr,
            &DualModuleParallelUnit<DualSerialModule, Queue>,
            &PrimalModuleSerial,
            Option<&GroupMaxUpdateLength>,
        ),
        Queue: FutureQueueMethods<Rational, Obstacle> + Default + std::fmt::Debug + Send + Sync + Clone,
    {
        if parallel_dual_module.config.enable_parallel_execution {
            // parallel implementation using rayon
            let thread_pool = Arc::clone(&self.thread_pool);
            *self.last_solve_start_time.write() = Instant::now();
            thread_pool.scope(|_| {
                (0..self.partition_info.config.partitions.len())
                .into_par_iter()
                .for_each( |unit_index| {
                    let unit_ptr = self.units[unit_index].clone();
                    unit_ptr.individual_solve::<DualSerialModule, Queue, F>(
                        self, 
                        PartitionedSyndromePattern::new(&syndrome_pattern), 
                        parallel_dual_module, 
                        &mut None,
                    );
                })
            });


            thread_pool.scope(|_| {
                (self.partition_info.config.partitions.len()..self.partition_info.units.len())
                .into_par_iter()
                .for_each( |unit_index| {
                    if (unit_index - self.partition_info.config.partitions.len()) % 2 == 0 {
                        let unit_ptr = self.units[unit_index].clone();
                        unit_ptr.fuse_and_solve::<DualSerialModule, Queue, F>(
                            self, 
                            PartitionedSyndromePattern::new(&syndrome_pattern), 
                            parallel_dual_module, 
                            &mut None,
                        );
                    }
                })
            });

            for unit_index in self.partition_info.config.partitions.len()..self.partition_info.units.len() {
                if (unit_index - self.partition_info.config.partitions.len()) % 2 == 1 {
                    let unit_ptr = self.units[unit_index].clone();
                    unit_ptr.fuse_and_solve::<DualSerialModule, Queue, F>(
                        self, 
                        PartitionedSyndromePattern::new(&syndrome_pattern), 
                        parallel_dual_module, 
                        &mut None,
                    );
                }
            }
        } else {
            // // sequential implementation
            for unit_index in 0..self.partition_info.config.partitions.len(){
                let unit_ptr = self.units[unit_index].clone();
                unit_ptr.individual_solve::<DualSerialModule, Queue, F>(
                    self, 
                    PartitionedSyndromePattern::new(&syndrome_pattern), 
                    parallel_dual_module, 
                    &mut Some(&mut callback),
                );
            }

            for unit_index in self.partition_info.config.partitions.len()..self.partition_info.units.len() {
                let unit_ptr = self.units[unit_index].clone();
                unit_ptr.fuse_and_solve::<DualSerialModule, Queue, F>(
                    self, 
                    PartitionedSyndromePattern::new(&syndrome_pattern), 
                    parallel_dual_module, 
                    &mut Some(&mut callback),
                );
            }
        }
        
        // thread_pool.scope(|_| {
        //     (self.partition_info.config.partitions.len()..self.partition_info.units.len())
        //     .into_par_iter()
        //     .for_each( |unit_index| {
        //         if (unit_index - self.partition_info.config.partitions.len()) % 2 == 1 {
        //             let unit_ptr = self.units[unit_index].clone();
        //             unit_ptr.fuse_and_solve::<DualSerialModule, Queue, F>(
        //                 self, 
        //                 PartitionedSyndromePattern::new(&syndrome_pattern), 
        //                 parallel_dual_module, 
        //                 &mut None,
        //             );
        //         }
        //     })
        // });

    }

}

impl PrimalModuleImpl for PrimalModuleParallel {
    /// create a primal module given the dual module
    fn new_empty(_solver_initializer: &SolverInitializer) -> Self {
        // use new_config directly instead
        unimplemented!()
        // Self::new_config(
        //     solver_initializer,
        //     &PartitionConfig::new(solver_initializer.vertex_num).info(),
        //     PrimalModuleParallelConfig::default(),
        //     growing_strategy,
        //     plugins,
        // )
    }

    /// clear all states; however this method is not necessarily called when load a new decoding problem, so you need to call it yourself
    fn clear(&mut self) {
        self.thread_pool.scope(|_| {
            self.units.par_iter().enumerate().for_each(|(_unit_idx, unit_ptr)| {
                let mut unit = unit_ptr.write();
                unit.clear();
            });
        });
    }

    /// load a new decoding problem given dual interface: note that all nodes MUST be defect node
    /// this function needs to be written to allow dynamic fusion
    fn load<D: DualModuleImpl>(&mut self, _interface_ptr: &DualModuleInterfacePtr, _dual_module: &mut D) {
        panic!("load interface directly into the parallel primal module is forbidden, use `individual_solve` instead");
    }

    /// analyze the reason why dual module cannot further grow, update primal data structure (alternating tree, temporary matches, etc)
    /// and then tell dual module what to do to resolve these conflicts;
    /// note that this function doesn't necessarily resolve all the conflicts, but can return early if some major change is made.
    /// when implementing this function, it's recommended that you resolve as many conflicts as possible.
    ///
    /// note: this is only ran in the "search" mode
    fn resolve(
        &mut self,
        _group_max_update_length: GroupMaxUpdateLength,
        _interface: &DualModuleInterfacePtr,
        _dual_module: &mut impl DualModuleImpl,
    ) -> bool {
        panic!("parallel primal module cannot handle global resolve requests, use `individual_solve` instead");
    }

    /// resolve the conflicts in the "tune" mode
    fn resolve_tune(
        &mut self,
        _group_max_update_length: BTreeSet<MaxUpdateLength>,
        _interface: &DualModuleInterfacePtr,
        _dual_module: &mut impl DualModuleImpl,
    ) -> (BTreeSet<MaxUpdateLength>, bool) {
        panic!("`resolve_tune` not implemented, this primal module does not work with tuning mode");
    }

    fn solve(
        &mut self,
        interface: &DualModuleInterfacePtr,
        syndrome_pattern: Arc<SyndromePattern>,
        dual_module: &mut impl DualModuleImpl,
    ) {
        self.solve_step_callback(interface, syndrome_pattern, dual_module, |_, _, _, _| {})
    }

    fn subgraph(&mut self, _interface: &DualModuleInterfacePtr)
        -> InternalSubgraph 
    {
        // sequential implementation for debugging purposes
        let mut subgraph = vec![];
        for unit_ptr in self.units.iter() {
            let mut unit = unit_ptr.write();
            // println!("unit: {:?}", unit.unit_index);
            let interface_ptr = unit.interface_ptr.clone();
            subgraph.extend(unit.subgraph(&interface_ptr))
        }
        subgraph

        // // // implementation using rayon
        // self.thread_pool.scope(|_| {
        //     let results: Vec<_> = 
        //         self.units.par_iter().filter_map(| unit_ptr| {
        //             let mut unit = unit_ptr.write();
        //             let interface_ptr = unit.interface_ptr.clone();
        //             Some(unit.subgraph(&interface_ptr, seed))
        //         }).collect();
        //     let mut final_subgraph: Vec<EdgeWeak> = vec![];
        //     for local_subgraph in results.into_iter() {
        //         final_subgraph.extend(local_subgraph);
        //     }
        //     final_subgraph
        // })
    }

    fn subgraph_range(
        &mut self,
        interface: &DualModuleInterfacePtr,
    ) -> (InternalSubgraph, WeightRange) {
        let subgraph = self.subgraph(interface);
        let mut upper = Rational::zero();
        for edge_weak in subgraph.iter() {
            // weight += self.weighted_edges[edge_index as usize].weight;
            // println!("{:?} edge in subgraph: {:?}, weight: {:?}", i, edge_weak.upgrade_force().read_recursive().edge_index, edge_weak.upgrade_force().read_recursive().weight);
            upper += edge_weak.upgrade_force().read_recursive().weight;
        }

        // let lower = self.units.last().unwrap().read_recursive().interface_ptr.sum_dual_variables();

        let mut lower = Rational::zero();
        for unit_ptr in self.units.iter() {
            let unit = unit_ptr.read_recursive();
            // println!("unit interface ptr sum dual variables: {:?}", unit.interface_ptr.sum_dual_variables());
            lower += unit.interface_ptr.sum_dual_variables();
        }

        let weight_range = WeightRange::new(
            lower,
            upper
        );

        (subgraph, weight_range)
    }

    /// performance profiler report
    fn generate_profiler_report(&self) -> serde_json::Value {
        let event_time_vec: Vec<_> = self.units.iter().map(|ptr| ptr.read_recursive().event_time.clone()).collect::<Vec<_>>();
        json!({
            "event_time_vec": event_time_vec,
        })
    }
}

impl PrimalModuleImpl for PrimalModuleParallelUnit {
    /// create a primal module given the dual module
    /// this function needs to be implemented for dynamic fusion
    fn new_empty(_solver_initializer: &SolverInitializer) -> Self {
        // we need this to create primal_module for newly (additionally) added unit
        panic!("creating parallel unit directly from initializer is forbidden, use `PrimalModuleParallel::new` instead");
    }

    /// clear all states; however this method is not necessarily called when load a new decoding problem, so you need to call it yourself
    fn clear(&mut self) {
        self.serial_module.clear();
        self.interface_ptr.clear();
    }

    /// load a new decoding problem given dual interface: note that all nodes MUST be defect node
    fn load<D: DualModuleImpl>(&mut self, interface_ptr: &DualModuleInterfacePtr, dual_module: &mut D) {
        self.serial_module.load(interface_ptr, dual_module);
    }

    /// analyze the reason why dual module cannot further grow, update primal data structure (alternating tree, temporary matches, etc)
    /// and then tell dual module what to do to resolve these conflicts;
    /// note that this function doesn't necessarily resolve all the conflicts, but can return early if some major change is made.
    /// when implementing this function, it's recommended that you resolve as many conflicts as possible.
    ///
    /// note: this is only ran in the "search" mode
    fn resolve(
        &mut self,
        group_max_update_length: GroupMaxUpdateLength,
        interface: &DualModuleInterfacePtr,
        dual_module: &mut impl DualModuleImpl,
    ) -> bool {
        self.serial_module.resolve(group_max_update_length, interface, dual_module)
    }

    /// resolve the conflicts in the "tune" mode
    fn resolve_tune(
        &mut self,
        group_max_update_length: BTreeSet<MaxUpdateLength>,
        interface: &DualModuleInterfacePtr,
        dual_module: &mut impl DualModuleImpl,
    ) -> (BTreeSet<MaxUpdateLength>, bool) {
        self.serial_module.resolve_tune(group_max_update_length, interface, dual_module)
    }

    fn subgraph(&mut self, interface: &DualModuleInterfacePtr)
        -> InternalSubgraph 
    {
        // println!("\nfn subgraph for unit: {:?}", self.unit_index);
        self.serial_module.subgraph(interface)
    }

    fn subgraph_range(
        &mut self,
        interface: &DualModuleInterfacePtr,
    ) -> (InternalSubgraph, WeightRange) {
        self.serial_module.subgraph_range(interface)
    }
}



impl MWPSVisualizer for PrimalModuleParallel {
    fn snapshot(&self, abbrev: bool) -> serde_json::Value {
        // do the sanity check first before taking snapshot
        // self.sanity_check().unwrap();
        let mut value = json!({});
        for unit_ptr in self.units.iter() {
            let unit = unit_ptr.read_recursive();
            // if !unit.is_active {
            //     continue;
            // } // do not visualize inactive units
            let value_2 = unit.snapshot(abbrev);
            snapshot_combine_values(&mut value, value_2, abbrev);
        }
        value
    }
}

impl MWPSVisualizer for PrimalModuleParallelUnit {
    fn snapshot(&self, abbrev: bool) -> serde_json::Value {
        self.serial_module.snapshot(abbrev)
    }
}



#[cfg(test)]
pub mod tests {
    use hashbrown::HashMap;
    use serde::de;

    use super::super::example_codes::*;
    use super::super::primal_module::*;

    use super::super::primal_module_serial::*;
    use crate::decoding_hypergraph::*;
    use super::*;
    use crate::num_traits::FromPrimitive;

    use crate::plugin_single_hair::PluginSingleHair;
    use crate::plugin_union_find::PluginUnionFind;
    use crate::plugin::PluginVec;
    // use crate::dual_module_serial::*;
    use crate::dual_module_pq::*;
    use std::usize::MAX;
    
    pub fn primal_module_parallel_basic_standard_syndrome(
        code: impl ExampleCode,
        visualize_filename: String,
        defect_vertices: Vec<VertexIndex>,
        final_dual: Weight,
        plugins: PluginVec,
        growing_strategy: GrowingStrategy,
    ) -> (
        PrimalModuleParallel,
        impl DualModuleImpl + MWPSVisualizer,
    ) {
        println!("{defect_vertices:?}");
        let visualizer = {
            let visualizer = Visualizer::new(
                Some(visualize_data_folder() + visualize_filename.as_str()),
                code.get_positions(),
                true,
            )
            .unwrap();
            print_visualize_link(visualize_filename.clone());
            visualizer
        };

        // create dual module
        let model_graph = code.get_model_graph();
        let initializer = &model_graph.initializer;
        let mut partition_config = PartitionConfig::new(initializer.vertex_num);
        partition_config.partitions = vec![
            VertexRange::new(0, 18),   // unit 0
            VertexRange::new(24, 42), // unit 1
        ];
        partition_config.fusions = vec![
                    (0, 1), // unit 2, by fusing 0 and 1
                ];
        let a = partition_config.dag_partition_units.add_node(());
        let b = partition_config.dag_partition_units.add_node(());
        partition_config.dag_partition_units.add_edge(a, b, false);
        partition_config.defect_vertices = BTreeSet::from_iter(defect_vertices.clone());

        let partition_info = partition_config.info();


        let mut dual_module_parallel_config = DualModuleParallelConfig::default();
        // dual_module_parallel_config.enable_parallel_execution = true;
        let dual_module: DualModuleParallel<DualModulePQ<FutureObstacleQueue<Rational>>, FutureObstacleQueue<Rational>> =
            DualModuleParallel::new_config(&initializer, &partition_info, dual_module_parallel_config);

        // create primal module
        let mut primal_config = PrimalModuleParallelConfig {..Default::default()};
        primal_config.timeout = 7.0;
        let primal_module = PrimalModuleParallel::new_config(&model_graph.initializer, &partition_info, primal_config.clone(), growing_strategy, Arc::new(plugins.clone()));
        // primal_module.growing_strategy = growing_strategy;
        // primal_module.plugins = Arc::new(plugins);
        // primal_module.config = serde_json::from_value(json!({"timeout":1})).unwrap();

        primal_module_parallel_basic_standard_syndrome_optional_viz(
            code,
            defect_vertices,
            final_dual,
            plugins,
            growing_strategy,
            dual_module,
            primal_module,
            model_graph,
            None,
        )
    }

    #[allow(clippy::too_many_arguments)]
    pub fn primal_module_parallel_basic_standard_syndrome_optional_viz<Queue>
    (
        _code: impl ExampleCode,
        defect_vertices: Vec<VertexIndex>,
        final_dual: Weight,
        _plugins: PluginVec,
        _growing_strategy: GrowingStrategy,
        mut dual_module: DualModuleParallel<DualModulePQ<Queue>, Queue>,
        mut primal_module: PrimalModuleParallel,
        model_graph: Arc<crate::model_hypergraph::ModelHyperGraph>,
        mut visualizer: Option<Visualizer>,
    ) -> (
        PrimalModuleParallel,
        impl DualModuleImpl + MWPSVisualizer,
    ) 
    where Queue: FutureQueueMethods<Rational, Obstacle> + Default + std::fmt::Debug + Send + Sync + Clone,
    {
        // try to work on a simple syndrome
        let decoding_graph = DecodingHyperGraph::new_defects(model_graph, defect_vertices.clone());
        let begin_time = std::time::Instant::now();
        primal_module.parallel_solve_visualizer(
            decoding_graph.syndrome_pattern.clone(),
            &mut dual_module,
            visualizer.as_mut(),
        );

        let useless_interface_ptr = DualModuleInterfacePtr::new();
        let (subgraph, weight_range) = primal_module.subgraph_range(&useless_interface_ptr);
        let subgraph_by_index: Vec<usize> = subgraph.iter().map(|e| e.upgrade_force().read_recursive().edge_index).collect();
        if let Some(visualizer) = visualizer.as_mut() {
            let last_interface_ptr = &primal_module.units.last().unwrap().read_recursive().interface_ptr;
            visualizer
                .snapshot_combined(
                    "subgraph".to_string(),
                    vec![last_interface_ptr, &dual_module, &subgraph, &weight_range],
                )
                .unwrap();
        }
        assert!(
            decoding_graph
                .model_graph
                .matches_subgraph_syndrome(&subgraph_by_index, &defect_vertices),
            "the result subgraph is invalid"
        );
        primal_module.clear();
        dual_module.clear();
        let end_time = std::time::Instant::now();
        let resolve_time = (end_time - begin_time);
        println!("resolve time {:?}", resolve_time);

        // assert_eq!(
        //     Rational::from_usize(final_dual).unwrap(),
        //     weight_range.upper,
        //     "unmatched sum dual variables"
        // );
        // assert_eq!(
        //     Rational::from_usize(final_dual).unwrap(),
        //     weight_range.lower,
        //     "unexpected final dual variable sum"
        // );
        (primal_module, dual_module)
    }

    /// test a simple case
    #[test]
    fn primal_module_parallel_tentative_test_1() {
        // RUST_BACKTRACE=1 cargo test primal_module_parallel_tentative_test_1 -- --nocapture
        let weight = 1; // do not change, the data is hard-coded
        let code = CodeCapacityPlanarCode::new(7, 0.1, weight);
        let defect_vertices = vec![13, 20, 29, 32, 39];

        let visualize_filename = "primal_module_parallel_tentative_test_1.json".to_string();
        primal_module_parallel_basic_standard_syndrome(
            code,
            visualize_filename,
            defect_vertices,
            5,
            vec![],
            GrowingStrategy::ModeBased,
        );
    }

    /// test a simple case
    #[test]
    fn primal_module_parallel_tentative_test_2() {
        // RUST_BACKTRACE=1 cargo test primal_module_parallel_tentative_test_2 -- --nocapture
        let weight = 1; // do not change, the data is hard-coded
        let code = CodeCapacityPlanarCode::new(7, 0.1, weight);
        let defect_vertices = vec![7, 21, 28];

        let visualize_filename = "primal_module_parallel_tentative_test_2.json".to_string();
        primal_module_parallel_basic_standard_syndrome(
            code,
            visualize_filename,
            defect_vertices,
            4,
            vec![],
            GrowingStrategy::ModeBased,
        );
    }

    /// test a simple case, split into 2, no defect vertex in boundary-unit, clusters do not grow into other units
    #[test]
    fn primal_module_parallel_tentative_test_3() {
        // RUST_BACKTRACE=1 cargo test primal_module_parallel_tentative_test_3 -- --nocapture
        let weight = 1; // do not change, the data is hard-coded
        let code = CodeCapacityPlanarCode::new(7, 0.1, weight);
        let defect_vertices = vec![2, 35];

        let visualize_filename = "primal_module_parallel_tentative_test_3.json".to_string();
        primal_module_parallel_basic_standard_syndrome(
            code,
            visualize_filename,
            defect_vertices,
            4,
            vec![],
            GrowingStrategy::ModeBased,
        );
    }

    // test a simple case, split into 2, a defect vertex in boundary-unit, clusters do grow into other units
    #[test]
    fn primal_module_parallel_tentative_test_4() {
        // RUST_BACKTRACE=1 cargo test primal_module_parallel_tentative_test_4 -- --nocapture
        let weight = 1; // do not change, the data is hard-coded
        let code = CodeCapacityPlanarCode::new(7, 0.1, weight);
        let defect_vertices = vec![19, 35];

        let visualize_filename = "primal_module_parallel_tentative_test_4.json".to_string();
        primal_module_parallel_basic_standard_syndrome(
            code,
            visualize_filename,
            defect_vertices,
            3,
            vec![],
            GrowingStrategy::ModeBased,
        );
    }

    #[test]
    fn primal_module_parallel_tentative_test_5() {
        // RUST_BACKTRACE=1 cargo test primal_module_parallel_tentative_test_5 -- --nocapture
        let weight = 1; // do not change, the data is hard-coded
        for seed in 0..1000 {
            let mut code = CodeCapacityPlanarCode::new(7, 0.1, weight);
            let defect_vertices = code.generate_random_errors(seed).0.defect_vertices;
            // let defect_vertices = vec![16, 19, 29, 39];
    
            let visualize_filename = "primal_module_parallel_tentative_test_5.json".to_string();
            primal_module_parallel_basic_standard_syndrome(
                code,
                visualize_filename,
                defect_vertices,
                8,
                vec![],
                GrowingStrategy::ModeBased,
            );
        }
    }

    #[test]
    fn primal_module_parallel_tentative_test_6() {
        // RUST_BACKTRACE=1 cargo test primal_module_parallel_tentative_test_6 -- --nocapture
        let weight = 1; // do not change, the data is hard-coded
        let code = CodeCapacityPlanarCode::new(7, 0.1, weight);
        let defect_vertices = vec![16, 19, 29, 32, 39];

        let visualize_filename = "primal_module_parallel_tentative_test_6.json".to_string();
        primal_module_parallel_basic_standard_syndrome(
            code,
            visualize_filename,
            defect_vertices,
            7,
            vec![],
            GrowingStrategy::ModeBased,
        );
    }

    pub fn primal_module_parallel_basic_standard_syndrome_split_into_4(
        code: impl ExampleCode,
        visualize_filename: String,
        defect_vertices: Vec<VertexIndex>,
        final_dual: Weight,
        plugins: PluginVec,
        growing_strategy: GrowingStrategy,
    ) -> (
        PrimalModuleParallel,
        impl DualModuleImpl + MWPSVisualizer,
    ) {
        println!("{defect_vertices:?}");
        let visualizer = {
            let visualizer = Visualizer::new(
                Some(visualize_data_folder() + visualize_filename.as_str()),
                code.get_positions(),
                true,
            )
            .unwrap();
            print_visualize_link(visualize_filename.clone());
            visualizer
        };

        // create model graph 
        let model_graph = code.get_model_graph();
        let initializer = &model_graph.initializer;
        let mut partition_config = PartitionConfig::new(initializer.vertex_num);
        partition_config.partitions = vec![
            VertexRange::new(0, 6),   // unit 0
            VertexRange::new(12, 18), // unit 1
            VertexRange::new(24, 30), // unit 2
            VertexRange::new(36, 42), // unit 3
        ];
        partition_config.fusions = vec![
                    (0, 1), // unit 4, by fusing 0 and 1
                    (1, 2), // unit 5, 
                    (2, 3), // unit 6
                ];
        let a = partition_config.dag_partition_units.add_node(());
        let b = partition_config.dag_partition_units.add_node(());
        let c = partition_config.dag_partition_units.add_node(());
        let d = partition_config.dag_partition_units.add_node(());
        partition_config.dag_partition_units.add_edge(a, b, false);
        partition_config.dag_partition_units.add_edge(b, c, false);
        partition_config.dag_partition_units.add_edge(c, d, false);
        
        partition_config.defect_vertices = BTreeSet::from_iter(defect_vertices.clone());

        let partition_info = partition_config.info();

        let mut dual_module_parallel_config = DualModuleParallelConfig::default();
        dual_module_parallel_config.enable_parallel_execution = false;
        let dual_module: DualModuleParallel<DualModulePQ<FutureObstacleQueue<Rational>>, FutureObstacleQueue<Rational>> =
            DualModuleParallel::new_config(&initializer, &partition_info, dual_module_parallel_config);

        // create primal module
        let primal_config = PrimalModuleParallelConfig {..Default::default()};
        let primal_module = PrimalModuleParallel::new_config(&model_graph.initializer, &partition_info, primal_config.clone(), growing_strategy, Arc::new(plugins.clone()));
        // primal_module.growing_strategy = growing_strategy;
        // primal_module.plugins = Arc::new(plugins);
        // primal_module.config = serde_json::from_value(json!({"timeout":1})).unwrap();

        primal_module_parallel_basic_standard_syndrome_optional_viz(
            code,
            defect_vertices,
            final_dual,
            plugins,
            growing_strategy,
            dual_module,
            primal_module,
            model_graph,
            Some(visualizer),
        )
    }

    /// test a simple case, split into 4, a defect vertex in boundary-unit, clusters grow into other units
    #[test]
    fn primal_module_parallel_split_into_4_test_7() {
        // RUST_BACKTRACE=1 cargo test -r primal_module_parallel_split_into_4_test_7 -- --nocapture
        let weight = 1; // do not change, the data is hard-coded
        for seed in 0..1000 {
            let mut code = CodeCapacityPlanarCode::new(7, 0.1, weight);
            let defect_vertices = code.generate_random_errors(seed).0.defect_vertices;
            // let defect_vertices = vec![13, 20, 29, 32, 39];
    
            let visualize_filename = "primal_module_parallel_split_into_4_test_7.json".to_string();
            primal_module_parallel_basic_standard_syndrome_split_into_4(
                code,
                visualize_filename,
                defect_vertices,
                9,
                vec![],
                GrowingStrategy::ModeBased,
            );
        }
       
    }


    /// test for time partition
    #[allow(clippy::unnecessary_cast)]
    pub fn graph_time_partition(initializer: &SolverInitializer, positions: &Vec<VisualizePosition>, defect_vertices: &Vec<VertexIndex>, split_num: usize) -> (PartitionConfig, usize)  {
        assert!(positions.len() > 0, "positive number of positions");
        let mut partition_config = PartitionConfig::new(initializer.vertex_num);
        let mut last_t = positions[0].t;
        let mut no_per_layer = 0;
        let mut t_list: Vec<f64> = vec![];
        t_list.push(last_t);
        for position in positions {
            assert!(position.t >= last_t, "t not monotonically increasing, vertex reordering must be performed before calling this");
            if position.t != last_t {
                t_list.push(position.t);
            } else if position.t == positions[0].t {
                no_per_layer += 1;
            }
            last_t = position.t;
        }

        // pick the t value in the middle to split it
        let mut t_split_vec: Vec<f64> = vec![0.0; split_num - 1];
        for i in 0..(split_num - 1) {
            let index: usize = t_list.len()/split_num * (i + 1);
            t_split_vec[i] = t_list[index];
        }
        // find the vertices indices
        let mut split_start_index_vec = vec![MAX; split_num - 1];
        let mut split_end_index_vec = vec![MAX; split_num - 1];
        let mut start_index = 0;
        let mut end_index = 0;
        for (vertex_index, position) in positions.iter().enumerate() {
            // println!("position: {:?}", position);
            if start_index < split_num - 1 {
                if split_start_index_vec[start_index] == MAX && position.t == t_split_vec[start_index] {
                    split_start_index_vec[start_index] = vertex_index;
                    if start_index != 0 {
                        end_index += 1;
                    }
                    start_index += 1;
                }
            }
            
            if end_index < split_num - 1 {
                if position.t == t_split_vec[end_index] {
                    split_end_index_vec[end_index] = vertex_index + 1;
                    // end_index += 1;
                }
            }
        }

        assert!(split_start_index_vec.iter().all(|&x| x != MAX), "Some elements in split_start_index_vec are equal to MAX");
        
        // partitions are found
        let mut graph_nodes = vec![];
        let mut partitions_vec = vec![];
        for i in 0..split_num  {
            if i == 0 {
                partitions_vec.push(VertexRange::new(0, split_start_index_vec[0]));
            } else if i == split_num - 1 {
                partitions_vec.push(VertexRange::new(split_end_index_vec[i - 1], positions.len()));
            } else {
                partitions_vec.push(VertexRange::new(split_end_index_vec[i - 1], split_start_index_vec[i]));
            }

            if i < split_num - 1 {
                partition_config.fusions.push((i, i+1));
            }
            
            let a = partition_config.dag_partition_units.add_node(());
            graph_nodes.push(a.clone());
        }
        partition_config.partitions = partitions_vec;

        for i in 0..split_num {
            if i < split_num - 1 {
                partition_config.dag_partition_units.add_edge(graph_nodes[i], graph_nodes[i+1], false);
            }
        }
        partition_config.defect_vertices = BTreeSet::from_iter(defect_vertices.clone());

        (partition_config, no_per_layer)
    }

    pub fn primal_module_parallel_evaluation_qec_playground_helper(
        code: impl ExampleCode,
        visualize_filename: String,
        defect_vertices: Vec<VertexIndex>,
        final_dual: Weight,
        plugins: PluginVec,
        growing_strategy: GrowingStrategy,
        split_num: usize,
    ) -> (
        PrimalModuleParallel,
        impl DualModuleImpl + MWPSVisualizer,
    ) {
        println!("{defect_vertices:?}");
        let visualizer = {
            let visualizer = Visualizer::new(
                Some(visualize_data_folder() + visualize_filename.as_str()),
                code.get_positions(),
                true,
            )
            .unwrap();
            print_visualize_link(visualize_filename.clone());
            visualizer
        };

        // create dual module
        let model_graph = code.get_model_graph();
        let initializer = &model_graph.initializer;
        let (partition_config , no_per_layer)= graph_time_partition(&initializer, &code.get_positions(), &defect_vertices, split_num);
        let partition_info = partition_config.info();


        // create dual module
        // let decoding_graph = DecodingHyperGraph::new_defects(model_graph.clone(), vec![3, 29, 30]);
        let mut dual_module_parallel_config = DualModuleParallelConfig::default();
        // dual_module_parallel_config.enable_parallel_execution = true;
        let mut dual_module: DualModuleParallel<DualModulePQ<FutureObstacleQueue<Rational>>, FutureObstacleQueue<Rational>> =
            DualModuleParallel::new_config(&initializer, &partition_info, dual_module_parallel_config);

        // create primal module
        let mut primal_config = PrimalModuleParallelConfig {..Default::default()};
        primal_config.thread_pool_size = 4;
        let primal_module = PrimalModuleParallel::new_config(&model_graph.initializer, &partition_info, primal_config.clone(), growing_strategy, Arc::new(plugins.clone()));

        primal_module_parallel_basic_standard_syndrome_optional_viz(
            code,
            defect_vertices,
            final_dual,
            plugins,
            growing_strategy,
            dual_module,
            primal_module,
            model_graph,
            Some(visualizer),
        )
    }

    #[test]
    fn primal_module_parallel_circuit_level_noise_qec_playground_1() {
        // cargo test primal_module_parallel_circuit_level_noise_qec_playground_1 -- --nocapture
        let config = json!({
            "code_type": qecp::code_builder::CodeType::RotatedPlanarCode
        });
        
        let code = QECPlaygroundCode::new(5, 0.01, config);
        let defect_vertices = vec![11, 12, 19];

        let visualize_filename = "primal_module_parallel_circuit_level_noise_qec_playground_1.json".to_string();
        primal_module_parallel_evaluation_qec_playground_helper(
            code,
            visualize_filename,
            defect_vertices,
            782027,
            vec![],
            GrowingStrategy::ModeBased,
            2,
        );
    }

    /// test solver on circuit level noise with random errors, split into 2
    #[test]
    fn primal_module_parallel_circuit_level_noise_qec_playground_2() {
        // cargo test -r primal_module_parallel_circuit_level_noise_qec_playground_2 -- --nocapture
        let config = json!({
            "code_type": qecp::code_builder::CodeType::RotatedPlanarCode,
            "nm": 2000,
        });
        
        let mut code = QECPlaygroundCode::new(7, 0.005, config);
        let defect_vertices = code.generate_random_errors(132).0.defect_vertices;

        let visualize_filename = "primal_module_parallel_circuit_level_noise_qec_playground_2.json".to_string();
        primal_module_parallel_evaluation_qec_playground_helper(
            code,
            visualize_filename,
            defect_vertices.clone(),
            9844651,
            vec![],
            GrowingStrategy::ModeBased,
            4,
        );
    }

    /// test solver on circuit level noise with random errors, split into 4
    #[test]
    fn primal_module_parallel_circuit_level_noise_qec_playground_3() {
        // cargo test -r primal_module_parallel_circuit_level_noise_qec_playground_3 -- --nocapture
        let config = json!({
            "code_type": qecp::code_builder::CodeType::RotatedPlanarCode,
            "nm": 500,
        });
        
        let mut code = QECPlaygroundCode::new(5, 0.005, config);
        let defect_vertices = code.generate_random_errors(132).0.defect_vertices;

        let visualize_filename = "primal_module_parallel_circuit_level_noise_qec_playground_3.json".to_string();
        primal_module_parallel_evaluation_qec_playground_helper(
            code,
            visualize_filename,
            defect_vertices.clone(),
            2424788,
            vec![],
            GrowingStrategy::ModeBased,
            4,
        );
    }

    /// test solver on circuit level noise with random errors, split into 8
    #[test]
    fn primal_module_parallel_circuit_level_noise_qec_playground_4() {
        // cargo test primal_module_parallel_circuit_level_noise_qec_playground_4 -- --nocapture
        let config = json!({
            "code_type": qecp::code_builder::CodeType::RotatedPlanarCode,
            "nm": 18,
        });
        
        let mut code = QECPlaygroundCode::new(5, 0.005, config);
        let defect_vertices = code.generate_random_errors(132).0.defect_vertices;

        // let defect_vertices = vec![16, 26, 29, 37, 39, 44, 46, 47, 51, 52, 54, 67, 122, 151];

        let visualize_filename = "primal_module_parallel_circuit_level_noise_qec_playground_4.json".to_string();
        primal_module_parallel_evaluation_qec_playground_helper(
            code,
            visualize_filename,
            defect_vertices.clone(),
            2424788,
            vec![],
            GrowingStrategy::ModeBased,
            8,
        );

        // for seed in 0..500 {
        //     let defect_vertices = code.clone().generate_random_errors(seed).0.defect_vertices;

        //     let visualize_filename = "primal_module_parallel_circuit_level_noise_qec_playground_4.json".to_string();
        //     primal_module_parallel_evaluation_qec_playground_helper(
        //         code.clone(),
        //         visualize_filename,
        //         defect_vertices.clone(),
        //         2424788,
        //         vec![],
        //         GrowingStrategy::ModeBased,
        //         8,
        //     );
        // }
        
    }



    // we now try to test for the case where there is newly (additionally) added unit 
    pub fn primal_module_parallel_additional_added_unit_helper_1(
        code: impl ExampleCode,
        new_code: impl ExampleCode,
        visualize_filename: String,
        defect_vertices: Vec<VertexIndex>,
        new_defect_vertices: Vec<VertexIndex>,
        final_dual: Weight,
        new_final_dual: Weight,
        plugins: PluginVec,
        new_plugins: PluginVec,
        growing_strategy: GrowingStrategy,
        new_growing_strategy: GrowingStrategy,
    ){
        println!("{defect_vertices:?}");
        let visualizer = {
            let visualizer = Visualizer::new(
                Some(visualize_data_folder() + visualize_filename.as_str()),
                code.get_positions(),
                true,
            )
            .unwrap();
            print_visualize_link(visualize_filename.clone());
            visualizer
        };

        // create dual module for the original units
        let growing_strategy = GrowingStrategy::ModeBased;
        let plugins = vec![];
        let model_graph = code.get_model_graph();
        let initializer = &model_graph.initializer;
        let mut partition_config = PartitionConfig::new(initializer.vertex_num);
        partition_config.partitions = vec![
            VertexRange::new(0, 18),   // unit 0
            VertexRange::new(24, 42), // unit 1
        ];
        partition_config.fusions = vec![
                    (0, 1), // unit 2, by fusing 0 and 1
                ];
        let a = partition_config.dag_partition_units.add_node(());
        let b = partition_config.dag_partition_units.add_node(());
        partition_config.dag_partition_units.add_edge(a, b, false);
        partition_config.defect_vertices = BTreeSet::from_iter(defect_vertices.clone());
        let partition_info = partition_config.info();
        let mut dual_module_parallel_config = DualModuleParallelConfig::default();
        // dual_module_parallel_config.enable_parallel_execution = true;
        let dual_module: DualModuleParallel<DualModulePQ<FutureObstacleQueue<Rational>>, FutureObstacleQueue<Rational>> =
            DualModuleParallel::new_config(&initializer, &partition_info, dual_module_parallel_config);
        // create primal module for original units
        let mut primal_config = PrimalModuleParallelConfig {..Default::default()};
        primal_config.timeout = 7.0;
        let primal_module = PrimalModuleParallel::new_config(&model_graph.initializer, &partition_info, primal_config.clone(), growing_strategy, Arc::new(plugins.clone()));

        // now we initialize the primal/dual modules and solve for the additionally added unit
        let new_growing_strategy = GrowingStrategy::ModeBased;
        let new_plugins = vec![];
        let new_model_graph = new_code.get_model_graph();
        let new_initializer = &new_model_graph.initializer;
        let mut new_partition_config = PartitionConfig::new(new_initializer.vertex_num);
        new_partition_config.partitions = vec![VertexRange::new(36, 42)];
        new_partition_config.fusions = vec![
                    (0, 1), // fuse self (this additional unit) with unit_index 1 in the original unit
        ];
        new_partition_config.defect_vertices = BTreeSet::from_iter(new_defect_vertices.clone());
        let new_boundary_vertices = VertexRange::new(0, 10); // need to check this
        let new_partition_info = new_partition_config.info_seperate(3, new_boundary_vertices);
        let mut new_dual_module_parallel_config = DualModuleParallelConfig::default();
        let new_dual_module: DualModuleParallelUnit<DualModulePQ<FutureObstacleQueue<Rational>>, FutureObstacleQueue<Rational>> = DualModuleParallelUnit::new_seperate_config(&new_initializer, &new_partition_info, new_dual_module_parallel_config);
        // create primal module for additional
        let mut new_primal_config = PrimalModuleParallelConfig {..Default::default()};
        new_primal_config.timeout = 7.0;
        let new_primal_module = PrimalModuleParallelUnit::new_config(&new_initializer, &new_partition_info, new_primal_config.clone(), new_growing_strategy, Arc::new(new_plugins.clone()));
        let new_primal_module_ptr = PrimalModuleParallelUnitPtr::new_value(new_primal_module);

        primal_module_parallel_additional_added_unit_helper_2(
            defect_vertices,
            new_defect_vertices,
            final_dual,
            new_final_dual,
            dual_module,
            new_dual_module,
            primal_module,
            new_primal_module_ptr,
            model_graph,
            new_model_graph,
            Some(visualizer),
            0, // not used if it is not circuit level noise 
            &new_partition_info,
        )
    }

    #[allow(clippy::too_many_arguments)]
    pub fn primal_module_parallel_additional_added_unit_helper_2<Queue>
    (
        defect_vertices: Vec<VertexIndex>,
        new_defect_vertices: Vec<VertexIndex>,
        final_dual: Weight,
        new_final_dual: Weight,
        mut dual_module: DualModuleParallel<DualModulePQ<Queue>, Queue>,
        mut new_dual_module: DualModuleParallelUnit<DualModulePQ<Queue>, Queue>,
        mut primal_module: PrimalModuleParallel,
        mut new_primal_module_ptr: PrimalModuleParallelUnitPtr,
        model_graph: Arc<crate::model_hypergraph::ModelHyperGraph>,
        new_model_graph: Arc<crate::model_hypergraph::ModelHyperGraph>,
        mut visualizer: Option<Visualizer>,
        no_per_layer: usize,
        new_partition_info: &PartitionInfo,
    ) 
    where Queue: FutureQueueMethods<Rational, Obstacle> + Default + std::fmt::Debug + Send + Sync + Clone,
    {
        // solve the original block 
        let decoding_graph = DecodingHyperGraph::new_defects(model_graph, defect_vertices.clone());
        let begin_time = std::time::Instant::now();
        primal_module.parallel_solve_visualizer(
            decoding_graph.syndrome_pattern.clone(),
            &mut dual_module,
            None,
        );

        // solve the new block
        let new_decoding_graph = DecodingHyperGraph::new_defects(new_model_graph, new_defect_vertices.clone());
        new_primal_module_ptr.seperate_parallel_solve_visualizer(
            new_decoding_graph.syndrome_pattern.clone(),
            &mut new_dual_module,
            &primal_module,
            &dual_module,
            new_partition_info,
            no_per_layer,
            None,
        );
 
        // let useless_interface_ptr = DualModuleInterfacePtr::new();
        // let (subgraph, weight_range) = primal_module.subgraph_range(&useless_interface_ptr, 0);

        // if let Some(visualizer) = visualizer.as_mut() {
        //     let last_interface_ptr = &primal_module.units.last().unwrap().read_recursive().interface_ptr;
        //     visualizer
        //         .snapshot_combined(
        //             "subgraph".to_string(),
        //             vec![last_interface_ptr, &dual_module, &subgraph, &weight_range],
        //         )
        //         .unwrap();
        // }
        let mut new_primal_module: &mut PrimalModuleParallelUnit = &mut new_primal_module_ptr.write();
        let useless_interface_ptr = DualModuleInterfacePtr::new();
        let (subgraph, weight_range) = new_primal_module.subgraph_range(&useless_interface_ptr);

        if let Some(visualizer) = visualizer.as_mut() {
            let last_interface_ptr = &new_primal_module.interface_ptr;
            visualizer
                .snapshot_combined(
                    "subgraph".to_string(),
                    vec![last_interface_ptr, &new_dual_module, &subgraph, &weight_range],
                )
                .unwrap();
        }
        // assert!(
        //     decoding_graph
        //         .model_graph
        //         .matches_subgraph_syndrome(&subgraph, &defect_vertices),
        //     "the result subgraph is invalid"
        // );
        primal_module.clear();
        dual_module.clear();
        new_primal_module_ptr.write().clear();
        new_dual_module.clear();
    }


    /// test a simple case
    #[test]
    fn primal_module_parallel_additional_added_unit_test_1() {
        // RUST_BACKTRACE=1 cargo test primal_module_parallel_additional_added_unit_test_1 -- --nocapture
        let visualize_filename = "primal_module_parallel_additional_added_unit_test_1.json".to_string();
        // for the original units
        let weight = 1; // do not change, the data is hard-coded
        let code = CodeCapacityPlanarCode::new(7, 0.1, weight);
        let defect_vertices = vec![13, 20, 29, 32, 39];

        // for the newly added units
        let new_weight = 1;
        let new_code = CodeCapacityPlanarCode::new(7, 0.1, new_weight);
        let new_defect_vertices = vec![13, 20];
        
        primal_module_parallel_additional_added_unit_helper_1(
            code,
            new_code,
            visualize_filename,
            defect_vertices,
            new_defect_vertices,
            5,
            5,
            vec![],
            vec![],
            GrowingStrategy::ModeBased,
            GrowingStrategy::ModeBased,
        )
    }

    /// for newly added space-time chunk 
    pub fn primal_module_parallel_circuit_level_noise_helper(
        code: impl ExampleCode,
        new_code: impl ExampleCode,
        visualize_filename: String,
        defect_vertices: Vec<VertexIndex>,
        new_defect_vertices: Vec<VertexIndex>,
        final_dual: Weight,
        new_final_dual: Weight,
        plugins: PluginVec,
        new_plugins: PluginVec,
        growing_strategy: GrowingStrategy,
        new_growing_strategy: GrowingStrategy,
        split_num: usize,
    ){
        println!("{defect_vertices:?}");
        let visualizer = {
            let visualizer = Visualizer::new(
                Some(visualize_data_folder() + visualize_filename.as_str()),
                code.get_positions(),
                true,
            )
            .unwrap();
            print_visualize_link(visualize_filename.clone());
            visualizer
        };

        // create dual module
        let model_graph = code.get_model_graph();
        let initializer = &model_graph.initializer;
        let (partition_config, no_per_layer) = graph_time_partition(&initializer, &code.get_positions(), &defect_vertices, split_num);
        let partition_info = partition_config.info();


        // create dual module
        // let decoding_graph = DecodingHyperGraph::new_defects(model_graph.clone(), vec![3, 29, 30]);
        let mut dual_module_parallel_config = DualModuleParallelConfig::default();
        // dual_module_parallel_config.enable_parallel_execution = true;
        let mut dual_module: DualModuleParallel<DualModulePQ<FutureObstacleQueue<Rational>>, FutureObstacleQueue<Rational>> =
            DualModuleParallel::new_config(&initializer, &partition_info, dual_module_parallel_config);

        // create primal module
        let mut primal_config = PrimalModuleParallelConfig {..Default::default()};
        primal_config.thread_pool_size = 4;
        let primal_module = PrimalModuleParallel::new_config(&model_graph.initializer, &partition_info, primal_config.clone(), growing_strategy, Arc::new(plugins.clone()));

        // now we initialize the primal/dual modules and solve for the additionally added unit
        let new_growing_strategy = GrowingStrategy::ModeBased;
        let new_plugins = vec![];
        let new_model_graph = new_code.get_model_graph();
        let new_initializer = &new_model_graph.initializer;
        let mut new_partition_config = PartitionConfig::new(new_initializer.vertex_num);
        new_partition_config.partitions = vec![VertexRange::new(36, 42)];
        new_partition_config.fusions = vec![
                    (0, 1), // fuse self (this additional unit) with unit_index 1 in the original unit
        ];
        new_partition_config.defect_vertices = BTreeSet::from_iter(new_defect_vertices.clone());
        let new_boundary_vertices = VertexRange::new(0, 10); // need to check this
        let new_partition_info = new_partition_config.info_seperate(3, new_boundary_vertices);
        let mut new_dual_module_parallel_config = DualModuleParallelConfig::default();
        let new_dual_module: DualModuleParallelUnit<DualModulePQ<FutureObstacleQueue<Rational>>, FutureObstacleQueue<Rational>> = DualModuleParallelUnit::new_seperate_config(&new_initializer, &new_partition_info, new_dual_module_parallel_config);
        // create primal module for additional
        let mut new_primal_config = PrimalModuleParallelConfig {..Default::default()};
        new_primal_config.timeout = 7.0;
        let new_primal_module = PrimalModuleParallelUnit::new_config(&new_initializer, &new_partition_info, new_primal_config.clone(), new_growing_strategy, Arc::new(new_plugins.clone()));
        let new_primal_module_ptr = PrimalModuleParallelUnitPtr::new_value(new_primal_module);

        // we need to find the one-to-one mapping from the vertices in original space-time chunk to the vertices in the newly added space-time chunk
        // let mut fuse_map_key: Vec<usize> = vec![];
        // let mut fuse_map_value: Vec<usize> = vec![];
        // let original_positions = code.get_positions();
        // let new_positions = new_code.get_positions();

        primal_module_parallel_additional_added_unit_helper_2(
            defect_vertices,
            new_defect_vertices,
            final_dual,
            new_final_dual,
            dual_module,
            new_dual_module,
            primal_module,
            new_primal_module_ptr,
            model_graph,
            new_model_graph,
            Some(visualizer),
            no_per_layer,
            &new_partition_info,
        )
    }

    /// test a simple circuit level noise
    #[test]
    fn primal_module_parallel_additional_added_unit_test_2() {
        // RUST_BACKTRACE=1 cargo test primal_module_parallel_additional_added_unit_test_2 -- --nocapture
        let visualize_filename = "primal_module_parallel_additional_added_unit_test_2.json".to_string();
        // for the original units
        let config = json!({
            "code_type": qecp::code_builder::CodeType::RotatedPlanarCode,
            "nm": 18,
        });
        let mut code = QECPlaygroundCode::new(3, 0.005, config);
        let defect_vertices = code.generate_random_errors(132).0.defect_vertices;

        // for the newly added units
        let new_config = json!({
            "code_type": qecp::code_builder::CodeType::RotatedPlanarCode,
            "nm": 18,
        });
        let new_code = QECPlaygroundCode::new(3, 0.005, new_config);
        let new_defect_vertices = code.generate_random_errors(133).0.defect_vertices;

        primal_module_parallel_circuit_level_noise_helper(
            code, 
            new_code,
            visualize_filename,
            defect_vertices,
            new_defect_vertices,
            5,
            5,
            vec![],
            vec![],
            GrowingStrategy::ModeBased,
            GrowingStrategy::ModeBased,
            2
        )
    }
}