//! Parallel Primal Module
//! 
//! A parallel implementation of the primal module, by calling functions provided by the serial primal module
//! 

#![cfg_attr(feature = "unsafe_pointer", allow(dropping_references))]
use super::dual_module::*;
use super::dual_module_parallel::*;
use super::pointers::*;
use super::primal_module::*;
use super::primal_module_serial::*;
use super::util::*;
use super::visualize::*;
use crate::model_hypergraph::ModelHyperGraph;
use crate::rayon::prelude::*;
use serde::{Deserialize, Serialize};
use std::ops::DerefMut;
use std::sync::{Arc, Condvar, Mutex};
use std::time::{Duration, Instant};
use crate::num_traits::FromPrimitive;
use crate::plugin::*;

pub struct PrimalModuleParallel {
    /// the basic wrapped serial modules at the beginning, afterwards the fused units are appended after them
    pub units: Vec<PrimalModuleParallelUnitPtr>,
    /// local configuration
    pub config: PrimalModuleParallelConfig,
    /// partition information generated by the config
    pub partition_info: Arc<PartitionInfo>,
    /// thread pool used to execute async functions in parallel
    pub thread_pool: Arc<rayon::ThreadPool>,
    // /// the time of calling [`PrimalModuleParallel::parallel_solve_step_callback`] method
    // pub last_solve_start_time: ArcRwLock<Instant>,
}

pub struct PrimalModuleParallelUnit {
    /// the index
    pub unit_index: usize,
    /// the dual module interface, for constant-time clear
    pub interface_ptr: DualModuleInterfacePtr,
    /// partition information generated by the config
    pub partition_info: Arc<PartitionInfo>,
    /// the owned serial primal module
    pub serial_module: PrimalModuleSerial,
    // /// record the time of events
    // pub event_time: Option<PrimalModuleParallelUnitEventTime>,
    // /// streaming decode mocker, if exists, base partition will wait until specified time and then start decoding
    // pub streaming_decode_mocker: Option<StreamingDecodeMocker>,
    /// adjacent parallel units
    pub adjacent_parallel_units: Vec<(PrimalModuleParallelUnitWeak, bool)>,
    /// whether this unit is solved 
    pub is_solved: bool,
}


pub type PrimalModuleParallelUnitPtr = ArcRwLock<PrimalModuleParallelUnit>;
pub type PrimalModuleParallelUnitWeak = WeakRwLock<PrimalModuleParallelUnit>;

impl std::fmt::Debug for PrimalModuleParallelUnitPtr {
    fn fmt(&self, f: &mut std::fmt::Formatter) -> std::fmt::Result {
        let unit = self.read_recursive();
        write!(f, "{}", unit.unit_index)
    }
}

impl std::fmt::Debug for PrimalModuleParallelUnitWeak {
    fn fmt(&self, f: &mut std::fmt::Formatter) -> std::fmt::Result {
        self.upgrade_force().fmt(f)
    }
}

#[derive(Debug, Clone, Serialize, Deserialize)]
#[serde(deny_unknown_fields)]
pub struct PrimalModuleParallelConfig {
    /// enable async execution of dual operations; only used when calling top-level operations, not used in individual units
    #[serde(default = "primal_module_parallel_default_configs::thread_pool_size")]
    pub thread_pool_size: usize,
    /// pin threads to cores sequentially
    #[serde(default = "primal_module_parallel_default_configs::pin_threads_to_cores")]
    pub pin_threads_to_cores: bool,
}

impl Default for PrimalModuleParallelConfig {
    fn default() -> Self {
        serde_json::from_value(json!({})).unwrap()
    }
}

pub mod primal_module_parallel_default_configs {
    pub fn thread_pool_size() -> usize {
        0
    } // by default to the number of CPU cores
      // pub fn thread_pool_size() -> usize { 1 }  // debug: use a single core
    pub fn pin_threads_to_cores() -> bool {
        false
    } // pin threads to cores to achieve most stable results
}

impl PrimalModuleParallel {
    pub fn new_config(
        initializer: &SolverInitializer,
        partition_info: &PartitionInfo,
        config: PrimalModuleParallelConfig,
        model_graph: &ModelHyperGraph,
    ) -> Self {
        let partition_info = Arc::new(partition_info.clone());
        let mut thread_pool_builder = rayon::ThreadPoolBuilder::new();
        if config.thread_pool_size != 0 {
            thread_pool_builder = thread_pool_builder.num_threads(config.thread_pool_size);
        }
        if config.pin_threads_to_cores {
            let core_ids = core_affinity::get_core_ids().unwrap();
            // println!("core_ids: {core_ids:?}");
            thread_pool_builder = thread_pool_builder.start_handler(move |thread_index| {
                // https://stackoverflow.com/questions/7274585/linux-find-out-hyper-threaded-core-id
                if thread_index < core_ids.len() {
                    crate::core_affinity::set_for_current(core_ids[thread_index]);
                } // otherwise let OS decide which core to execute
            });
        }

        // let partitioned_visualizers = &parallel_dual_module.partitioned_initializers;
        let thread_pool = thread_pool_builder.build().expect("creating thread pool failed");
        let mut units = vec![];
        let unit_count = partition_info.units.len();
        thread_pool.scope(|_| {
            (0..unit_count)
                .into_par_iter()
                .map(|unit_index| {
                    // println!("unit_index: {unit_index}");
                    // let model_graph = ModelHyperGraph::new_partitioned(&partitioned_visualizers[unit_index]);
                    let primal_module = PrimalModuleSerial::new_empty(initializer, &model_graph);
                    PrimalModuleParallelUnitPtr::new_wrapper(primal_module, unit_index, Arc::clone(&partition_info), model_graph.clone())
                })
                .collect_into_vec(&mut units);
        });

        // we need to fill in the adjacent_parallel_units here 
        for unit_index in 0..unit_count {
            let mut unit = units[unit_index].write();
            for adjacent_unit_index in partition_info.units[unit_index].adjacent_partition_units.clone().into_iter() {
                unit.adjacent_parallel_units.push((units[adjacent_unit_index].clone().downgrade(), false));
            }
        }

        Self {
            units,
            config,
            partition_info,
            thread_pool: Arc::new(thread_pool),
        }

    }
}

impl PrimalModuleParallelUnitPtr {
    /// create a simple wrapper over a serial dual module
    pub fn new_wrapper(serial_module: PrimalModuleSerial, unit_index: usize, partition_info: Arc<PartitionInfo>, model_graph: ModelHyperGraph) -> Self {
        // let partition_unit_info = &partition_info.units[unit_index];
        let interface_ptr = DualModuleInterfacePtr::new(model_graph.clone().into());
        interface_ptr.write().unit_index = unit_index;
        Self::new_value(PrimalModuleParallelUnit {
            unit_index,
            interface_ptr,
            partition_info,
            serial_module,
            adjacent_parallel_units: vec![],
            is_solved: false,
        })
    }

    // /// fuse two units together, by copying the content in other (primal and dual) into myself and resolve the index
    // /// note that this operation doesn't update on the dual module, call [`Self::break_matching_with_mirror`] if needed
    // pub fn fuse<DualSerialModule: DualModuleImpl + Send + Sync>(
    //     &mut self,
    //     dual_unit: &mut DualModuleParallelUnit<DualSerialModule>,
    //     other: &mut Self,
    //     other_dual_unit: &mut DualModuleParallelUnit<DualSerialModule>,
    // ) {
    //     dual_unit.fuse(&self.interface_ptr, &other.interface_ptr, &other_dual_unit);
    //     self.serial_module.fuse(&other.serial_module);
    // }

    fn individual_solve<DualSerialModule: DualModuleImpl + Send + Sync, F: Send + Sync>(
        &self,
        primal_module_parallel: &PrimalModuleParallel,
        partitioned_syndrome_pattern: PartitionedSyndromePattern,
        parallel_dual_module: &DualModuleParallel<DualSerialModule>,
        callback: &mut Option<&mut F>,
    ) where
        F: FnMut(
            &DualModuleInterfacePtr,
            &DualModuleParallelUnit<DualSerialModule>,
            &PrimalModuleSerial,
            Option<&GroupMaxUpdateLength>,
        ),
    {
        let mut primal_unit = self.write();
        println!("unit index: {}", primal_unit.unit_index);
        let dual_module_ptr = parallel_dual_module.get_unit(primal_unit.unit_index);
        let mut dual_unit = dual_module_ptr.write();
        let partition_unit_info = &primal_unit.partition_info.units[primal_unit.unit_index];
        let (owned_defect_range, _) = partitioned_syndrome_pattern.partition(partition_unit_info);
        let interface_ptr = primal_unit.interface_ptr.clone();

        // solve the individual unit first 
        if !primal_unit.is_solved {
            // we solve the individual unit first
            let syndrome_pattern = Arc::new(owned_defect_range.expand());
            primal_unit.serial_module.solve_step_callback(
                &interface_ptr,
                syndrome_pattern,
                dual_unit.deref_mut(),
                |interface, dual_module, primal_module, group_max_update_length| {
                    if let Some(callback) = callback.as_mut() {
                        callback(interface, dual_module, primal_module, Some(group_max_update_length));
                    }
                },
            );
            primal_unit.is_solved = true;
            if let Some(callback) = callback.as_mut() {
                callback(&primal_unit.interface_ptr, &dual_unit, &primal_unit.serial_module, None);
            }
        }
    }

    /// call this only if children is guaranteed to be ready and solved
    #[allow(clippy::unnecessary_cast)]
    fn fuse_and_solve<DualSerialModule: DualModuleImpl + Send + Sync, F: Send + Sync>(
        &self,
        primal_module_parallel: &PrimalModuleParallel,
        partitioned_syndrome_pattern: PartitionedSyndromePattern,
        parallel_dual_module: &DualModuleParallel<DualSerialModule>,
        callback: &mut Option<&mut F>,
    ) where
        F: FnMut(
            &DualModuleInterfacePtr,
            &DualModuleParallelUnit<DualSerialModule>,
            &PrimalModuleSerial,
            Option<&GroupMaxUpdateLength>,
        ),
    {
        let mut primal_unit = self.write();
        let dual_module_ptr = parallel_dual_module.get_unit(primal_unit.unit_index);
        let mut dual_unit = dual_module_ptr.write();
        let partition_unit_info = &primal_unit.partition_info.units[primal_unit.unit_index];
        let (owned_defect_range, _) = partitioned_syndrome_pattern.partition(partition_unit_info);
        let interface_ptr = primal_unit.interface_ptr.clone();

        assert!(primal_unit.is_solved, "this unit must have been solved before we fuse it with its neighbors");
        
        // this unit has been solved, we can fuse it with its adjacent units
        // we iterate through the dag_partition_unit to fuse units together 
        for adjacent_index in 0..primal_unit.adjacent_parallel_units.len() {
            let (ref adjacent_unit_weak, is_fused) = primal_unit.adjacent_parallel_units[adjacent_index];

            if is_fused {
                continue;
            }

            let adjacent_unit_ptr = adjacent_unit_weak.upgrade_force();
            let mut adjacent_unit = adjacent_unit_ptr.write();
            let adjacent_dual_unit_ptr = parallel_dual_module.get_unit(adjacent_unit.unit_index);
            let mut adjacent_dual_unit = adjacent_dual_unit_ptr.write();
            primal_unit.adjacent_parallel_units[adjacent_index].1 = true;
            dual_unit.adjacent_parallel_units[adjacent_index].1 = true;

            let mut primal_unit_interface_write = primal_unit.interface_ptr.write();
            primal_unit_interface_write.adjacent_parallel_units[adjacent_index].1 = true;

            // concatenate the owning_range of the 2 units
            dual_unit.owning_range = dual_unit.owning_range.fuse(&adjacent_dual_unit.owning_range).0;
            

            for adjacent_index0 in 0..adjacent_unit.adjacent_parallel_units.len() {
                let (ref adjacent_unit0_weak, is_fused0) = adjacent_unit.adjacent_parallel_units[adjacent_index0];
                if is_fused0 {
                    continue;
                }
                if adjacent_unit0_weak.upgrade_force().read().unit_index == primal_unit.unit_index {
                    adjacent_unit.adjacent_parallel_units[adjacent_index0].1 = true;
                    adjacent_dual_unit.adjacent_parallel_units[adjacent_index0].1 = true;
                    adjacent_unit.interface_ptr.write().adjacent_parallel_units[adjacent_index0].1 = true;
                    adjacent_dual_unit.owning_range = dual_unit.owning_range;

                    break;
                }
            }

            // primal_unit.fuse(&mut dual_unit, adjacent_unit.upgrade_force(), adjacent_dual_unit.write());

            if let Some(callback) = callback.as_mut() {
                // do callback before actually breaking the matched pairs, for ease of visualization
                callback(&primal_unit.interface_ptr, &dual_unit, &primal_unit.serial_module, None);
            }

            for boundary_vertex in primal_unit.adsf

            // primal_unit.break_matching_with_mirror(dual_unit.deref_mut());
            // for defect_index in owned_defect_range.whole_defect_range.iter() {
            //     let defect_vertex = partitioned_syndrome_pattern.syndrome_pattern.defect_vertices[defect_index as usize];
            //     primal_unit
            //         .serial_module
            //         .load_defect(defect_vertex, &interface_ptr, dual_unit.deref_mut());
            // }
        }

        // 


        primal_unit.serial_module.solve_step_callback_interface_loaded(
            &interface_ptr,
            dual_unit.deref_mut(),
            |interface, dual_module, primal_module, group_max_update_length| {
                if let Some(callback) = callback.as_mut() {
                    callback(interface, dual_module, primal_module, Some(group_max_update_length));
                }
            },
        );
        if let Some(callback) = callback.as_mut() {
            callback(&primal_unit.interface_ptr, &dual_unit, &primal_unit.serial_module, None);
        }
    }
}

impl PrimalModuleImpl for PrimalModuleParallel {
    /// create a primal module given the dual module
    fn new_empty(_solver_initializer: &SolverInitializer, _model_graph: &ModelHyperGraph) -> Self {
        // Self::new_config(
        //     solver_initializer,
        //     &PartitionConfig::new(solver_initializer.vertex_num).info(),
        //     PrimalModuleParallelConfig::default(),
        //     model_graph,
        // )
        panic!("call new_config in PrimalModuleParallel instead");
    }

    /// clear all states; however this method is not necessarily called when load a new decoding problem, so you need to call it yourself
    fn clear(&mut self) {
        self.thread_pool.scope(|_| {
            self.units.par_iter().enumerate().for_each(|(unit_idx, unit_ptr)| {
                let mut unit = unit_ptr.write();
                unit.clear();
            });
        });
    }

    /// load a new decoding problem given dual interface: note that all nodes MUST be defect node
    fn load<D: DualModuleImpl>(&mut self, interface_ptr: &DualModuleInterfacePtr, dual_module: &mut D) {
        panic!("load interface directly into the parallel primal module is forbidden, use `parallel_solve` instead");
    }

    /// analyze the reason why dual module cannot further grow, update primal data structure (alternating tree, temporary matches, etc)
    /// and then tell dual module what to do to resolve these conflicts;
    /// note that this function doesn't necessarily resolve all the conflicts, but can return early if some major change is made.
    /// when implementing this function, it's recommended that you resolve as many conflicts as possible.
    fn resolve(
        &mut self,
        group_max_update_length: GroupMaxUpdateLength,
        interface: &DualModuleInterfacePtr,
        dual_module: &mut impl DualModuleImpl,
    ) {
        panic!("parallel primal module cannot handle global resolve requests, use `parallel_solve` instead");
    }

    fn solve(
        &mut self,
        interface: &DualModuleInterfacePtr,
        syndrome_pattern: Arc<SyndromePattern>,
        dual_module: &mut impl DualModuleImpl,
    ) {
        self.solve_step_callback(interface, syndrome_pattern, dual_module, |_, _, _, _| {})
    }

    fn subgraph(&mut self, interface: &DualModuleInterfacePtr, dual_module: &mut impl DualModuleImpl) -> Subgraph {
        let mut subgraph = vec![];
        for unit_ptr in self.units.clone() {
            let mut unit = unit_ptr.write();
            subgraph.extend(unit.subgraph(interface, dual_module));
        }
        subgraph

        // self.thread_pool.scope(|_| {
        //     self.units.par_iter().enumerate().for_each(|(unit_idx, unit_ptr)| {
        //         let mut unit = unit_ptr.write();
        //         let partition_unit_info = &unit.partition_info.units[unit_idx];
        //         subgraph.extend(unit.subgraph(interface, dual_module));
        //     });
        // });
        // subgraph
    }

    // fn subgraph_range(
    //     &mut self,
    //     interface: &DualModuleInterfacePtr,
    //     dual_module: &mut impl DualModuleImpl,
    // ) -> (Subgraph, WeightRange) {
    //     let subgraph = self.subgraph(interface, dual_module);
    //     let weight_range = WeightRange::new(
    //         interface.sum_dual_variables(),
    //         Rational::from_usize(
    //             interface
    //                 .read_recursive()
    //                 .decoding_graph
    //                 .model_graph
    //                 .initializer
    //                 .get_subgraph_total_weight(&subgraph),
    //         )
    //         .unwrap(),
    //     );
    //     (subgraph, weight_range)
    // }

    /// performance profiler report
    fn generate_profiler_report(&self) -> serde_json::Value {
        json!({})
    }
}

impl PrimalModuleParallel {
    pub fn parallel_solve<DualSerialModule: DualModuleImpl + Send + Sync>(
        &mut self,
        syndrome_pattern: Arc<SyndromePattern>,
        parallel_dual_module: &DualModuleParallel<DualSerialModule>,
    ) {
        self.parallel_solve_step_callback(syndrome_pattern, parallel_dual_module, |_, _, _, _| {});
    }

    pub fn parallel_solve_visualizer<DualSerialModule: DualModuleImpl + Send + Sync + MWPSVisualizer>(
        &mut self,
        syndrome_pattern: Arc<SyndromePattern>,
        parallel_dual_module: &DualModuleParallel<DualSerialModule>,
        visualizer: Option<&mut Visualizer>,
    ) {
        if let Some(visualizer) = visualizer {
            self.parallel_solve_step_callback(
                syndrome_pattern,
                parallel_dual_module,
                |interface, dual_module, primal_module, group_max_update_length| {
                    if let Some(group_max_update_length) = group_max_update_length {
                        if cfg!(debug_assertions) {
                            println!("group_max_update_length: {:?}", group_max_update_length);
                        }
                        if group_max_update_length.is_unbounded() {
                            visualizer
                                .snapshot_combined("unbounded grow".to_string(), vec![interface, dual_module, primal_module])
                                .unwrap();
                        } else if let Some(length) = group_max_update_length.get_valid_growth() {
                            visualizer
                                .snapshot_combined(format!("grow {length}"), vec![interface, dual_module, primal_module])
                                .unwrap();
                        } else {
                            let first_conflict = format!("{:?}", group_max_update_length.peek().unwrap());
                            visualizer
                                .snapshot_combined(
                                    format!("resolve {first_conflict}"),
                                    vec![interface, dual_module, primal_module],
                                )
                                .unwrap();
                        };
                    } else {
                        visualizer
                            .snapshot_combined("unit solved".to_string(), vec![interface, dual_module, primal_module])
                            .unwrap();
                    }
                    
                },
            );
            let last_unit = self.units.last().unwrap().read_recursive();
            visualizer
                .snapshot_combined(
                    "solved".to_string(),
                    vec![&last_unit.interface_ptr, parallel_dual_module, self],
                )
                .unwrap();
        } else {
            self.parallel_solve(syndrome_pattern, parallel_dual_module);
        }
    }

    pub fn parallel_solve_step_callback<DualSerialModule: DualModuleImpl + Send + Sync, F: Send + Sync>(
        &mut self,
        syndrome_pattern: Arc<SyndromePattern>,
        parallel_dual_module: &DualModuleParallel<DualSerialModule>,
        mut callback: F,
    ) where
        F: FnMut(
            &DualModuleInterfacePtr,
            &DualModuleParallelUnit<DualSerialModule>,
            &PrimalModuleSerial,
            Option<&GroupMaxUpdateLength>,
        ),
    {
        // let thread_pool = Arc::clone(&self.thread_pool);
        for unit_index in 0..self.partition_info.units.len() {
            let unit_ptr = self.units[unit_index].clone();
            unit_ptr.individual_solve::<DualSerialModule, F>(
                self, 
                PartitionedSyndromePattern::new(&syndrome_pattern), 
                parallel_dual_module, 
                &mut Some(&mut callback),
            );
        }

        for unit_index in 0..self.partition_info.units.len() {
            let unit_ptr = self.units[unit_index].clone();
            unit_ptr.fuse_and_solve::<DualSerialModule, F>(
                self, 
                PartitionedSyndromePattern::new(&syndrome_pattern), 
                parallel_dual_module, 
                &mut Some(&mut callback),
            );
        }
    }
}

impl MWPSVisualizer for PrimalModuleParallel {
    fn snapshot(&self, abbrev: bool) -> serde_json::Value {
        // do the sanity check first before taking snapshot
        // self.sanity_check().unwrap();
        let mut value = json!({});
        for unit_ptr in self.units.iter() {
            let unit = unit_ptr.read_recursive();
            // if !unit.is_active {
            //     continue;
            // } // do not visualize inactive units
            let value_2 = unit.snapshot(abbrev);
            snapshot_combine_values(&mut value, value_2, abbrev);
        }
        value
    }
}

impl MWPSVisualizer for PrimalModuleParallelUnit {
    fn snapshot(&self, abbrev: bool) -> serde_json::Value {
        self.serial_module.snapshot(abbrev)
    }
}

impl PrimalModuleImpl for PrimalModuleParallelUnit {
    /// create a primal module given the dual module
    fn new_empty(_solver_initializer: &SolverInitializer, model_graph: &ModelHyperGraph) -> Self {
        panic!("creating parallel unit directly from initializer is forbidden, use `PrimalModuleParallel::new` instead");
    }

    /// clear all states; however this method is not necessarily called when load a new decoding problem, so you need to call it yourself
    fn clear(&mut self) {
        self.serial_module.clear();
        self.interface_ptr.clear();
    }

    /// load a new decoding problem given dual interface: note that all nodes MUST be defect node
    fn load<D: DualModuleImpl>(&mut self, interface_ptr: &DualModuleInterfacePtr, dual_module: &mut D) {
        self.serial_module.load(interface_ptr, dual_module);
    }

    /// analyze the reason why dual module cannot further grow, update primal data structure (alternating tree, temporary matches, etc)
    /// and then tell dual module what to do to resolve these conflicts;
    /// note that this function doesn't necessarily resolve all the conflicts, but can return early if some major change is made.
    /// when implementing this function, it's recommended that you resolve as many conflicts as possible.
    fn resolve(
        &mut self,
        group_max_update_length: GroupMaxUpdateLength,
        interface: &DualModuleInterfacePtr,
        dual_module: &mut impl DualModuleImpl,
    ) {
        self.serial_module.resolve(group_max_update_length, interface, dual_module);

    }

    fn subgraph(&mut self, interface: &DualModuleInterfacePtr, dual_module: &mut impl DualModuleImpl) -> Subgraph {
        self.serial_module.subgraph(interface, dual_module)
    }

    fn subgraph_range(
        &mut self,
        interface: &DualModuleInterfacePtr,
        dual_module: &mut impl DualModuleImpl,
    ) -> (Subgraph, WeightRange) {
        let subgraph = self.subgraph(interface, dual_module);
        let weight_range = WeightRange::new(
            interface.sum_dual_variables(),
            Rational::from_usize(
                interface
                    .read_recursive()
                    .decoding_graph
                    .model_graph
                    .initializer
                    .get_subgraph_total_weight(&subgraph),
            )
            .unwrap(),
        );
        (subgraph, weight_range)
    }

    /// performance profiler report
    fn generate_profiler_report(&self) -> serde_json::Value {
        json!({})
    }
}



#[cfg(test)]
pub mod tests {
    use super::super::example_codes::*;
    use super::super::primal_module::*;
    use super::super::primal_module_serial::*;
    use crate::decoding_hypergraph::*;
    use super::*;
    use crate::num_traits::FromPrimitive;

    use crate::plugin_single_hair::PluginSingleHair;
    use crate::plugin_union_find::PluginUnionFind;
    use crate::plugin::PluginVec;
    use crate::dual_module_serial::*;
    
    pub fn primal_module_parallel_basic_standard_syndrome(
        code: impl ExampleCode,
        visualize_filename: String,
        defect_vertices: Vec<VertexIndex>,
        final_dual: Weight,
        plugins: PluginVec,
        growing_strategy: GrowingStrategy,
    ) -> (
        DualModuleInterfacePtr,
        PrimalModuleParallel,
        impl DualModuleImpl + MWPSVisualizer,
    ) {
        println!("{defect_vertices:?}");
        let visualizer = {
            let visualizer = Visualizer::new(
                Some(visualize_data_folder() + visualize_filename.as_str()),
                code.get_positions(),
                true,
            )
            .unwrap();
            print_visualize_link(visualize_filename.clone());
            visualizer
        };

        // create dual module
        let model_graph = code.get_model_graph();
        let initializer = &model_graph.initializer;
        let mut partition_config = PartitionConfig::new(initializer.vertex_num);
        partition_config.partitions = vec![
            VertexRange::new(0, 18),   // unit 0
            VertexRange::new(24, 42), // unit 1
        ];
        partition_config.fusions = vec![
                    (0, 1), // unit 2, by fusing 0 and 1
                ];
        let partition_info = partition_config.info();
        let dual_module: DualModuleParallel<DualModuleSerial> =
            DualModuleParallel::new_config(&initializer, &partition_info, DualModuleParallelConfig::default());

        // create primal module
        let model_graph = code.get_model_graph();
        let primal_config = PrimalModuleParallelConfig {..Default::default()};
        let primal_module = PrimalModuleParallel::new_config(&model_graph.initializer, &partition_info, primal_config.clone(), &model_graph);

        // primal_module.growing_strategy = growing_strategy;
        // primal_module.plugins = Arc::new(plugins);
        // primal_module.config = serde_json::from_value(json!({"timeout":1})).unwrap();

        primal_module_parallel_basic_standard_syndrome_optional_viz(
            code,
            defect_vertices,
            final_dual,
            plugins,
            growing_strategy,
            dual_module,
            primal_module,
            model_graph,
            Some(visualizer),
        )
    }

    #[allow(clippy::too_many_arguments)]
    pub fn primal_module_parallel_basic_standard_syndrome_optional_viz(
        _code: impl ExampleCode,
        defect_vertices: Vec<VertexIndex>,
        final_dual: Weight,
        plugins: PluginVec,
        growing_strategy: GrowingStrategy,
        mut dual_module: DualModuleParallel<DualModuleSerial>,
        mut primal_module: PrimalModuleParallel,
        model_graph: Arc<crate::model_hypergraph::ModelHyperGraph>,
        mut visualizer: Option<Visualizer>,
    ) -> (
        DualModuleInterfacePtr,
        PrimalModuleParallel,
        impl DualModuleImpl + MWPSVisualizer,
    ) {
        // try to work on a simple syndrome
        let decoding_graph = DecodingHyperGraph::new_defects(model_graph, defect_vertices.clone());
        let interface_ptr = DualModuleInterfacePtr::new(decoding_graph.model_graph.clone());
        primal_module.parallel_solve_visualizer(
            decoding_graph.syndrome_pattern.clone(),
            &mut dual_module,
            visualizer.as_mut(),
        );


        let (subgraph, weight_range) = primal_module.subgraph_range(&interface_ptr, &mut dual_module);
        if let Some(visualizer) = visualizer.as_mut() {
            visualizer
                .snapshot_combined(
                    "subgraph".to_string(),
                    vec![&interface_ptr, &dual_module, &subgraph, &weight_range],
                )
                .unwrap();
        }
        // assert!(
        //     decoding_graph
        //         .model_graph
        //         .matches_subgraph_syndrome(&subgraph, &defect_vertices),
        //     "the result subgraph is invalid"
        // );
        // assert_eq!(
        //     Rational::from_usize(final_dual).unwrap(),
        //     weight_range.upper,
        //     "unmatched sum dual variables"
        // );
        // assert_eq!(
        //     Rational::from_usize(final_dual).unwrap(),
        //     weight_range.lower,
        //     "unexpected final dual variable sum"
        // );
        (interface_ptr, primal_module, dual_module)
    }

    /// test a simple case
    #[test]
    fn primal_module_parallel_tentative_test_1() {
        // RUST_BACKTRACE=1 cargo test primal_module_parallel_tentative_test_1 -- --nocapture
        let weight = 1; // do not change, the data is hard-coded
        // let pxy = 0.0602828812732227;
        let code = CodeCapacityPlanarCode::new(7, 0.1, weight);
        let defect_vertices = vec![15];

        let visualize_filename = "dual_module_parallel_tentative_test_3.json".to_string();
        primal_module_parallel_basic_standard_syndrome(
            code,
            visualize_filename,
            defect_vertices,
            4,
            vec![],
            GrowingStrategy::SingleCluster,
        );
    }

    #[test]
    fn dual_module_parallel_tentative_test_1() {
        // cargo test dual_module_parallel_tentative_test_1 -- --nocapture
        let visualize_filename = "dual_module_parallel_tentative_test_1.json".to_string();
        let weight = 600; // do not change, the data is hard-coded
        // let pxy = 0.0602828812732227;
        let code = CodeCapacityPlanarCode::new(7, 0.1, weight);
        let mut visualizer = Visualizer::new(
            Some(visualize_data_folder() + visualize_filename.as_str()),
            code.get_positions(),
            true,
        )
        .unwrap();
        print_visualize_link(visualize_filename);
        visualizer.snapshot("code".to_string(), &code).unwrap();

        // create dual module
        let model_graph = code.get_model_graph();
        let initializer = &model_graph.initializer;
        let mut partition_config = PartitionConfig::new(initializer.vertex_num);
        partition_config.partitions = vec![
            VertexRange::new(0, 18),   // unit 0
            VertexRange::new(24, 42), // unit 1
        ];
        partition_config.fusions = vec![
                    (0, 1), // unit 2, by fusing 0 and 1
                ];
        let a = partition_config.dag_partition_units.add_node(());
        let b = partition_config.dag_partition_units.add_node(());
        partition_config.dag_partition_units.add_edge(a, b, false);

        let partition_info = partition_config.info();

        // create dual module
        let mut dual_module: DualModuleParallel<DualModuleSerial> =
            DualModuleParallel::new_config(&initializer, &partition_info, DualModuleParallelConfig::default());
        
        // try to work on a simple syndrome
        let decoding_graph = DecodingHyperGraph::new_defects(model_graph, vec![3, 29, 30]);
        let interface_ptr = DualModuleInterfacePtr::new_load(decoding_graph, &mut dual_module);
        
        // println!("interface_ptr json: {}", interface_ptr.snapshot(false));
        // println!("dual_module json: {}", dual_module.snapshot(false));

        visualizer
            .snapshot_combined("syndrome".to_string(), vec![&interface_ptr, &dual_module])
            .unwrap();

        // grow them each by half
        let dual_node_3_ptr = interface_ptr.read_recursive().nodes[0].clone();
        let dual_node_12_ptr = interface_ptr.read_recursive().nodes[1].clone();
        let dual_node_30_ptr = interface_ptr.read_recursive().nodes[2].clone();
        dual_module.grow_dual_node(&dual_node_3_ptr, Rational::from_usize(weight / 2).unwrap());
        dual_module.grow_dual_node(&dual_node_12_ptr, Rational::from_usize(weight / 2).unwrap());
        dual_module.grow_dual_node(&dual_node_30_ptr, Rational::from_usize(weight / 2).unwrap());
        visualizer
            .snapshot_combined("grow".to_string(), vec![&interface_ptr, &dual_module])
            .unwrap();

        // cluster becomes solved
        dual_module.grow_dual_node(&dual_node_3_ptr, Rational::from_usize(weight / 2).unwrap());
        dual_module.grow_dual_node(&dual_node_12_ptr, Rational::from_usize(weight / 2).unwrap());
        dual_module.grow_dual_node(&dual_node_30_ptr, Rational::from_usize(weight / 2).unwrap());

        visualizer
            .snapshot_combined("solved".to_string(), vec![&interface_ptr, &dual_module])
            .unwrap();

        // the result subgraph
        let subgraph = vec![15, 20, 27];
        visualizer
            .snapshot_combined("subgraph".to_string(), vec![&interface_ptr, &dual_module, &subgraph])
            .unwrap();
    }

     // pub fn primal_module_parallel_basic_standard_syndrome(
    //     code: impl ExampleCode,
    //     visualize_filename: String,
    //     defect_vertices: Vec<VertexIndex>,
    //     final_dual: Weight,
    //     plugins: PluginVec,
    //     growing_strategy: GrowingStrategy,
    // ) -> (
    //     DualModuleInterfacePtr,
    //     PrimalModuleParallel,
    //     impl DualModuleImpl + MWPSVisualizer,
    // ) {
    //     println!("{defect_vertices:?}");
    //     let visualizer = {
    //         let visualizer = Visualizer::new(
    //             Some(visualize_data_folder() + visualize_filename.as_str()),
    //             code.get_positions(),
    //             true,
    //         )
    //         .unwrap();
    //         print_visualize_link(visualize_filename.clone());
    //         visualizer
    //     };

    //     // create dual module
    //     let model_graph = code.get_model_graph();
    //     let initializer = &model_graph.initializer;
    //     let mut partition_config = PartitionConfig::new(initializer.vertex_num);
    //     partition_config.partitions = vec![
    //         VertexRange::new(0, 18),   // unit 0
    //         VertexRange::new(24, 42), // unit 1
    //     ];
    //     partition_config.fusions = vec![
    //                 (0, 1), // unit 2, by fusing 0 and 1
    //             ];
    //     let partition_info = partition_config.info();
    //     let mut dual_module: DualModuleParallel<DualModuleSerial> =
    //         DualModuleParallel::new_config(&initializer, &partition_info, DualModuleParallelConfig::default());

    //     // create primal module
    //     let primal_config = PrimalModuleParallelConfig {..Default::default()};
    //     let mut primal_module = PrimalModuleParallel::new_config(&model_graph.initializer, &partition_info, primal_config.clone(), &model_graph);

    //     // primal_module.growing_strategy = growing_strategy;
    //     // primal_module.plugins = Arc::new(plugins);
    //     // primal_module.config = serde_json::from_value(json!({"timeout":1})).unwrap();
    //     // try to work on a simple syndrome
    //     let decoding_graph = DecodingHyperGraph::new_defects(model_graph, defect_vertices.clone());
    //     let interface_ptr = DualModuleInterfacePtr::new(decoding_graph.model_graph.clone());
    //     primal_module.parallel_solve_visualizer(
    //         decoding_graph.syndrome_pattern.clone(),
    //         &mut dual_module,
    //         Some(visualizer).as_mut(),
    //     );


    //     let (subgraph, weight_range) = primal_module.subgraph_range(&interface_ptr, &mut dual_module);
    //     // if let Some(visualizer) = Some(visualizer).as_mut() {
    //     //     visualizer
    //     //         .snapshot_combined(
    //     //             "subgraph".to_string(),
    //     //             vec![&interface_ptr, &dual_module, &subgraph, &weight_range],
    //     //         )
    //     //         .unwrap();
    //     // }
    //     // assert!(
    //     //     decoding_graph
    //     //         .model_graph
    //     //         .matches_subgraph_syndrome(&subgraph, &defect_vertices),
    //     //     "the result subgraph is invalid"
    //     // );
    //     // assert_eq!(
    //     //     Rational::from_usize(final_dual).unwrap(),
    //     //     weight_range.upper,
    //     //     "unmatched sum dual variables"
    //     // );
    //     // assert_eq!(
    //     //     Rational::from_usize(final_dual).unwrap(),
    //     //     weight_range.lower,
    //     //     "unexpected final dual variable sum"
    //     // );
    //     (interface_ptr, primal_module, dual_module)
    // }

}