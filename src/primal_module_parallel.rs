//! Parallel Primal Module
//! 
//! A parallel implementation of the primal module, by calling functions provided by the serial primal module
//! 

#![cfg_attr(feature = "unsafe_pointer", allow(dropping_references))]
use super::dual_module::*;
use super::dual_module_parallel::*;
use super::pointers::*;
use super::primal_module::*;
use super::primal_module_serial::*;
use super::util::*;
use super::visualize::*;
use crate::model_hypergraph::ModelHyperGraph;
use crate::mwpf_solver::hyperion_default_configs::primal;
use crate::rayon::prelude::*;
use serde::{Deserialize, Serialize};
use std::collections::BTreeMap;
use std::ops::DerefMut;
use std::sync::{Arc, Condvar, Mutex};
use std::time::{Duration, Instant};
use crate::num_traits::FromPrimitive;
use crate::plugin::*;
use crate::num_traits::One;
use weak_table::PtrWeakKeyHashMap;

pub struct PrimalModuleParallel {
    /// the basic wrapped serial modules at the beginning, afterwards the fused units are appended after them
    pub units: Vec<PrimalModuleParallelUnitPtr>,
    /// local configuration
    pub config: PrimalModuleParallelConfig,
    /// partition information generated by the config
    pub partition_info: Arc<PartitionInfo>,
    /// thread pool used to execute async functions in parallel
    pub thread_pool: Arc<rayon::ThreadPool>,
    // /// the time of calling [`PrimalModuleParallel::parallel_solve_step_callback`] method
    // pub last_solve_start_time: ArcRwLock<Instant>,
}

pub struct PrimalModuleParallelUnit {
    /// the index
    pub unit_index: usize,
    /// the dual module interface, for constant-time clear
    pub interface_ptr: DualModuleInterfacePtr,
    /// partition information generated by the config
    pub partition_info: Arc<PartitionInfo>,
    /// the owned serial primal module
    pub serial_module: PrimalModuleSerial,
    // /// record the time of events
    // pub event_time: Option<PrimalModuleParallelUnitEventTime>,
    // /// streaming decode mocker, if exists, base partition will wait until specified time and then start decoding
    // pub streaming_decode_mocker: Option<StreamingDecodeMocker>,
    /// adjacent parallel units
    pub adjacent_parallel_units: PtrWeakKeyHashMap<PrimalModuleParallelUnitWeak, bool>,
    /// whether this unit is solved 
    pub is_solved: bool,
}


pub type PrimalModuleParallelUnitPtr = ArcRwLock<PrimalModuleParallelUnit>;
pub type PrimalModuleParallelUnitWeak = WeakRwLock<PrimalModuleParallelUnit>;

impl std::fmt::Debug for PrimalModuleParallelUnitPtr {
    fn fmt(&self, f: &mut std::fmt::Formatter) -> std::fmt::Result {
        let unit = self.read_recursive();
        write!(f, "{}", unit.unit_index)
    }
}

impl std::fmt::Debug for PrimalModuleParallelUnitWeak {
    fn fmt(&self, f: &mut std::fmt::Formatter) -> std::fmt::Result {
        self.upgrade_force().fmt(f)
    }
}

#[derive(Debug, Clone, Serialize, Deserialize)]
#[serde(deny_unknown_fields)]
pub struct PrimalModuleParallelConfig {
    /// enable async execution of dual operations; only used when calling top-level operations, not used in individual units
    #[serde(default = "primal_module_parallel_default_configs::thread_pool_size")]
    pub thread_pool_size: usize,
    /// pin threads to cores sequentially
    #[serde(default = "primal_module_parallel_default_configs::pin_threads_to_cores")]
    pub pin_threads_to_cores: bool,
}

impl Default for PrimalModuleParallelConfig {
    fn default() -> Self {
        serde_json::from_value(json!({})).unwrap()
    }
}

pub mod primal_module_parallel_default_configs {
    pub fn thread_pool_size() -> usize {
        0
    } // by default to the number of CPU cores
      // pub fn thread_pool_size() -> usize { 1 }  // debug: use a single core
    pub fn pin_threads_to_cores() -> bool {
        false
    } // pin threads to cores to achieve most stable results
}

impl PrimalModuleParallel {
    pub fn new_config<DualSerialModule: DualModuleImpl + Send + Sync>(
        initializer: &SolverInitializer,
        partition_info: &PartitionInfo,
        config: PrimalModuleParallelConfig,
        // model_graph: &ModelHyperGraph,
        parallel_dual_module: &DualModuleParallel<DualSerialModule>,
    ) -> Self {
        let partition_info = Arc::new(partition_info.clone());
        let mut thread_pool_builder = rayon::ThreadPoolBuilder::new();
        if config.thread_pool_size != 0 {
            thread_pool_builder = thread_pool_builder.num_threads(config.thread_pool_size);
        }
        if config.pin_threads_to_cores {
            let core_ids = core_affinity::get_core_ids().unwrap();
            // println!("core_ids: {core_ids:?}");
            thread_pool_builder = thread_pool_builder.start_handler(move |thread_index| {
                // https://stackoverflow.com/questions/7274585/linux-find-out-hyper-threaded-core-id
                if thread_index < core_ids.len() {
                    crate::core_affinity::set_for_current(core_ids[thread_index]);
                } // otherwise let OS decide which core to execute
            });
        }

        let partitioned_initializers = &parallel_dual_module.partitioned_initializers;
        let thread_pool = thread_pool_builder.build().expect("creating thread pool failed");
        let mut units = vec![];
        let unit_count = partition_info.units.len();
        thread_pool.scope(|_| {
            (0..unit_count)
                .into_par_iter()
                .map(|unit_index| {
                    // println!("unit_index: {unit_index}");
                    let model_graph = ModelHyperGraph::new_partitioned(&partitioned_initializers[unit_index]);
                    let primal_module = PrimalModuleSerial::new_empty(initializer, &model_graph);
                    PrimalModuleParallelUnitPtr::new_wrapper(primal_module, unit_index, Arc::clone(&partition_info), model_graph.clone())
                })
                .collect_into_vec(&mut units);
        });

         // we need to fill in the adjacent_parallel_units here 
         for unit_index in 0..unit_count {
            let mut unit = units[unit_index].write();
            for adjacent_unit_index in partition_info.units[unit_index].adjacent_partition_units.clone().into_iter() {
                let adjacent_unit_ptr = &units[adjacent_unit_index];
                let adjacent_unit = adjacent_unit_ptr.read_recursive();
                let adjacent_interface = &adjacent_unit.interface_ptr;
                unit.interface_ptr.write().adjacent_parallel_units.insert(adjacent_interface.clone(), false);
                unit.adjacent_parallel_units.insert(adjacent_unit_ptr.clone(), false);

            }
        }



        Self {
            units,
            config,
            partition_info,
            thread_pool: Arc::new(thread_pool),
        }

    }
}

impl PrimalModuleParallelUnitPtr {
    /// create a simple wrapper over a serial dual module
    pub fn new_wrapper(serial_module: PrimalModuleSerial, unit_index: usize, partition_info: Arc<PartitionInfo>, model_graph: ModelHyperGraph) -> Self {
        // let partition_unit_info = &partition_info.units[unit_index];
        let interface_ptr = DualModuleInterfacePtr::new(model_graph.clone().into());
        let mut interface = interface_ptr.write();
        interface.unit_index = unit_index;
        Self::new_value(PrimalModuleParallelUnit {
            unit_index,
            interface_ptr: interface_ptr.clone(),
            partition_info,
            serial_module,
            adjacent_parallel_units: PtrWeakKeyHashMap::new(),
            is_solved: false,
        })
    }

    // /// fuse two units together, by copying the right child's content into the left child's content and resolve index;
    // /// note that this operation doesn't update on the dual module, call [`Self::break_matching_with_mirror`] if needed
    // pub fn fuse<DualSerialModule: DualModuleImpl + Send + Sync>(
    //     &mut self,
    //     dual_unit_ptr: &DualModuleParallelUnitPtr<DualSerialModule>,
    //     adjacent_unit_ptr: &Self,
    //     adjacent_dual_unit_ptr: &DualModuleParallelUnitPtr<DualSerialModule>,
    // ) {
    //     let mut dual_unit = dual_unit_ptr.write();
    //     dual_unit.fuse(&self.read_recursive().interface_ptr, &adjacent_unit_ptr.read_recursive().interface_ptr, adjacent_dual_unit_ptr);

    //     let mut adjacent_dual_unit = adjacent_dual_unit_ptr.write();
    //     let mut adjacent_unit = adjacent_unit_ptr.read_recursive();
    //     adjacent_dual_unit.fuse(&adjacent_unit.interface_ptr, &self.read_recursive().interface_ptr, dual_unit_ptr);
    //     // self.serial_module.fuse(&left_child.serial_module, &right_child.serial_module);
    // }

    // /// fuse two units together, by copying the content in other (primal and dual) into myself and resolve the index
    // /// note that this operation doesn't update on the dual module, call [`Self::break_matching_with_mirror`] if needed
    // pub fn fuse<DualSerialModule: DualModuleImpl + Send + Sync>(
    //     &mut self,
    //     dual_unit: &mut DualModuleParallelUnit<DualSerialModule>,
    //     other: &mut Self,
    //     other_dual_unit: &mut DualModuleParallelUnit<DualSerialModule>,
    // ) {
    //     dual_unit.fuse(&self.interface_ptr, &other.interface_ptr, &other_dual_unit);
    //     self.serial_module.fuse(&other.serial_module);
    // }

    fn individual_solve_and_fuse<DualSerialModule: DualModuleImpl + Send + Sync, F: Send + Sync>(
        &self,
        primal_module_parallel: &PrimalModuleParallel,
        partitioned_syndrome_pattern: PartitionedSyndromePattern,
        parallel_dual_module: &DualModuleParallel<DualSerialModule>,
        callback: &mut Option<&mut F>,
    ) where
        F: FnMut(
            &DualModuleInterfacePtr,
            &DualModuleParallelUnit<DualSerialModule>,
            &PrimalModuleSerial,
            Option<&GroupMaxUpdateLength>,
        ),
    {
        let mut primal_unit = self.write();
        let dual_module_ptr = parallel_dual_module.get_unit(primal_unit.unit_index);
        let mut dual_unit = dual_module_ptr.write();
        let partition_unit_info = &primal_unit.partition_info.units[primal_unit.unit_index];
        let (owned_defect_range, _) = partitioned_syndrome_pattern.partition(partition_unit_info);
        let interface_ptr = primal_unit.interface_ptr.clone();

        println!("unit index: {}", primal_unit.unit_index);
        if primal_unit.is_solved {
        //     // we proceed to fuse 
        //     println!("inside fuse_and_solve");
        //     // assert!(primal_unit.is_solved, "this unit must have been solved before we fuse it with its neighbors");
        //     println!("primal_unit.adjacent_parallel_units.len(): {}", primal_unit.adjacent_parallel_units.len());
        //     // this unit has been solved, we can fuse it with its adjacent units
        //     // we iterate through the dag_partition_unit to fuse units together 
        //     for adjacent_index in 0..primal_unit.adjacent_parallel_units.len() {
        //         let adjacent_unit_weak = &primal_unit.adjacent_parallel_units[adjacent_index].0;
        //         let adjacent_unit_ptr = adjacent_unit_weak.upgrade_force();
        //         let adjacent_dual_unit_ptr = parallel_dual_module.get_unit(adjacent_unit_ptr.read_recursive().unit_index);
        //         let mut adjacent_dual_unit = adjacent_dual_unit_ptr.write();

        //         primal_unit.fuse_with_adjacent(&mut dual_unit, adjacent_index, &mut adjacent_dual_unit);


        //         if let Some(callback) = callback.as_mut() {
        //             // do callback before actually breaking the matched pairs, for ease of visualization
        //             callback(&primal_unit.interface_ptr, &dual_unit, &primal_unit.serial_module, None);
        //         }

        //         primal_unit.break_matching_with_mirror(dual_unit.deref_mut());
        //         adjacent_unit_ptr.write().break_matching_with_mirror(adjacent_dual_unit.deref_mut());

        //         // let adjacent_partition_unit_info = &adjacent_unit.partition_info.units[adjacent_unit.unit_index];
        //         // let (adjacent_owned_defect_range, _) = partitioned_syndrome_pattern.partition(adjacent_partition_unit_info);

        //         // for defect_index in adjacent_owned_defect_range.whole_defect_range.iter() {
        //         //     let defect_vertex = partitioned_syndrome_pattern.syndrome_pattern.defect_vertices[defect_index as usize];
        //         //     primal_unit
        //         //         .serial_module
        //         //         .load_defect(defect_vertex, &interface_ptr, dual_unit.deref_mut());
        //         // }

        //         drop(adjacent_unit_ptr);
        
        //         primal_unit.serial_module.solve_step_callback_interface_loaded(
        //             &interface_ptr,
        //             dual_unit.deref_mut(),
        //             |interface, dual_module, primal_module, group_max_update_length| {
        //                 if let Some(callback) = callback.as_mut() {
        //                     callback(interface, dual_module, primal_module, Some(group_max_update_length));
        //                 }
        //             },
        //         );
        //         // if let Some(callback) = callback.as_mut() {
        //         //     callback(&primal_unit.interface_ptr, &dual_unit, &primal_unit.serial_module, None);
        //         // }
            // }
        } else{
            // we solve it first and set is_solved to true            
            if !primal_unit.is_solved {
                // we solve the individual unit first
                let syndrome_pattern = Arc::new(owned_defect_range.expand());
                primal_unit.serial_module.solve_step_callback(
                    &interface_ptr,
                    syndrome_pattern,
                    dual_unit.deref_mut(),
                    |interface, dual_module, primal_module, group_max_update_length| {
                        if let Some(callback) = callback.as_mut() {
                            callback(interface, dual_module, primal_module, Some(group_max_update_length));
                        }
                    },
                );
                primal_unit.is_solved = true;
                if let Some(callback) = callback.as_mut() {
                    callback(&primal_unit.interface_ptr, &dual_unit, &primal_unit.serial_module, None);
                }
            }
        }
    }

    fn individual_solve<DualSerialModule: DualModuleImpl + Send + Sync, F: Send + Sync>(
        &self,
        primal_module_parallel: &PrimalModuleParallel,
        partitioned_syndrome_pattern: PartitionedSyndromePattern,
        parallel_dual_module: &DualModuleParallel<DualSerialModule>,
        callback: &mut Option<&mut F>,
    ) where
        F: FnMut(
            &DualModuleInterfacePtr,
            &DualModuleParallelUnit<DualSerialModule>,
            &PrimalModuleSerial,
            Option<&GroupMaxUpdateLength>,
        ),
    {
        println!("inside individual_solve");
        let mut primal_unit = self.write();
        println!("unit index: {}", primal_unit.unit_index);
        let dual_module_ptr = parallel_dual_module.get_unit(primal_unit.unit_index);
        let mut dual_unit = dual_module_ptr.write();
        let partition_unit_info = &primal_unit.partition_info.units[primal_unit.unit_index];
        println!("owning_range: {} to {}", partition_unit_info.owning_range.range[0], partition_unit_info.owning_range.range[1]);
        let (owned_defect_range, _) = partitioned_syndrome_pattern.partition(partition_unit_info);
        println!("ownined_defect_range: {owned_defect_range:?}");
        let interface_ptr = primal_unit.interface_ptr.clone();

        // solve the individual unit first 
        if !primal_unit.is_solved {
            // we solve the individual unit first
            let syndrome_pattern = Arc::new(owned_defect_range.expand());
            println!("syndrom_pattern {syndrome_pattern:?}");
            primal_unit.serial_module.solve_step_callback(
                &interface_ptr,
                syndrome_pattern,
                dual_unit.deref_mut(),
                |interface, dual_module, primal_module, group_max_update_length| {
                    if let Some(callback) = callback.as_mut() {
                        callback(interface, dual_module, primal_module, Some(group_max_update_length));
                    }
                },
            );
            primal_unit.is_solved = true;
            if let Some(callback) = callback.as_mut() {
                callback(&primal_unit.interface_ptr, &dual_unit, &primal_unit.serial_module, None);
            }
        }
    }

    /// call this only if children is guaranteed to be ready and solved
    #[allow(clippy::unnecessary_cast)]
    fn fuse_and_solve<DualSerialModule: DualModuleImpl + Send + Sync, F: Send + Sync>(
        &self,
        primal_module_parallel: &PrimalModuleParallel,
        partitioned_syndrome_pattern: PartitionedSyndromePattern,
        parallel_dual_module: &DualModuleParallel<DualSerialModule>,
        callback: &mut Option<&mut F>,
    ) where
        F: FnMut(
            &DualModuleInterfacePtr,
            &DualModuleParallelUnit<DualSerialModule>,
            &PrimalModuleSerial,
            Option<&GroupMaxUpdateLength>,
        ),
    {
        println!("inside fuse_and_solve");
        let mut primal_unit = self.write();
        let dual_module_ptr = parallel_dual_module.get_unit(primal_unit.unit_index);
        let mut dual_unit = dual_module_ptr.write();
        let partition_unit_info = &primal_unit.partition_info.units[primal_unit.unit_index];
        let (owned_defect_range, _) = partitioned_syndrome_pattern.partition(partition_unit_info);
        let interface_ptr = primal_unit.interface_ptr.clone();

        assert!(primal_unit.is_solved, "this unit must have been solved before we fuse it with its neighbors");
        
        println!("primal_unit.adjacent_parallel_units.len(): {}", primal_unit.adjacent_parallel_units.len());
        // this unit has been solved, we can fuse it with its adjacent units
        // we iterate through the dag_partition_unit to fuse units together 
        for (adjacent_unit_ptr, is_fused) in primal_unit.adjacent_parallel_units.clone().iter() {
            if *is_fused {
                continue;
            }

            let mut adjacent_unit = adjacent_unit_ptr.write();
            let adjacent_dual_unit_ptr = parallel_dual_module.get_unit(adjacent_unit.unit_index);
            let mut adjacent_dual_unit = adjacent_dual_unit_ptr.write();

            println!("hello");
            // modify dual_module and interface
            if let Some(is_fused) = dual_unit.adjacent_parallel_units.get_mut(&adjacent_dual_unit_ptr) {
                *is_fused = true;
            }     
          
            println!("fuse asdf");
            // now we fuse the interface (copying the interface of other to myself)
            let mut interface = interface_ptr.write();
            // fuse dual interface 
            if let Some(is_fused) = interface.adjacent_parallel_units.get_mut(&adjacent_unit.interface_ptr) {
                *is_fused = true;
            }
            drop(interface);


            // primal_unit.fuse(&mut dual_module_ptr, &adjacent_unit_ptr.write(), &mut adjacent_dual_unit_ptr);

            println!("hello1");
            // modify primal
            if let Some(is_fused0) = primal_unit.adjacent_parallel_units.get_mut(&adjacent_unit_ptr) {
                *is_fused0 = true;
            }
            // modify primal
            if let Some(is_fused0) = adjacent_unit.adjacent_parallel_units.get_mut(&self) {
                *is_fused0 = true;
            }

            println!("hello2");
            // bias the index of both primal and the dual nodes of the adjacent unit 
            let bias_primal = primal_unit.serial_module.nodes.len();
            let bias_dual = dual_unit.serial_module.nodes.len();
            adjacent_dual_unit.serial_module.bias_dual_node_index(bias_dual);

            for cluster_ptr in adjacent_unit.serial_module.clusters.iter() {
                let mut cluster = cluster_ptr.write();
                cluster.cluster_index += bias_primal;
            }

            primal_unit.break_matching_with_mirror(dual_unit.deref_mut());
            adjacent_unit.break_matching_with_mirror(adjacent_dual_unit.deref_mut());

            drop(adjacent_unit);
            drop(adjacent_dual_unit);
            //     // let adjacent_partition_unit_info = &adjacent_unit.partition_info.units[adjacent_unit.unit_index];
            //     // let (adjacent_owned_defect_range, _) = partitioned_syndrome_pattern.partition(adjacent_partition_unit_info);

            //     // for defect_index in adjacent_owned_defect_range.whole_defect_range.iter() {
            //     //     let defect_vertex = partitioned_syndrome_pattern.syndrome_pattern.defect_vertices[defect_index as usize];
            //     //     primal_unit
            //     //         .serial_module
            //     //         .load_defect(defect_vertex, &interface_ptr, dual_unit.deref_mut());
            //     // }
    
            // }

           
        }
        println!("done fusion");
        // for defect_index in owned_defect_range.whole_defect_range.iter() {
        //     let defect_vertex = partitioned_syndrome_pattern.syndrome_pattern.defect_vertices[defect_index as usize];
        //     primal_unit
        //         .serial_module
        //         .load_defect(defect_vertex, &interface_ptr, dual_unit.deref_mut());
        // }

        primal_unit.serial_module.solve_step_callback_interface_loaded(
            &interface_ptr,
            dual_unit.deref_mut(),
            |interface, dual_module, primal_module, group_max_update_length| {
                if let Some(callback) = callback.as_mut() {
                    callback(interface, dual_module, primal_module, Some(group_max_update_length));
                }
            },
        );
        // if let Some(callback) = callback.as_mut() {
        //     callback(&primal_unit.interface_ptr, &dual_unit, &primal_unit.serial_module, None);
        // }

        drop(primal_unit);
        // drop(dual_unit);
        
    }

    // // /// fuse two units together, by copying the right child's content into the left child's content and resolve index;
    // // /// note that this operation doesn't update on the dual module, call [`Self::break_matching_with_mirror`] if needed
    // pub fn fuse<DualSerialModule: DualModuleImpl + Send + Sync>(
    //     &mut self,
    //     dual_unit: &mut DualModuleParallelUnitPtr<DualSerialModule>,
    //     adjacent_unit: &Self,
    //     adjacent_dual_unit: &mut DualModuleParallelUnitPtr<DualSerialModule>,
    // ) {
    //     // fuse dual unit
    //     if let Some(is_fused) = self.adjacent_parallel_units.get_mut(other_dual_unit) {
    //         *is_fused = true;
    //     }
    //     dual_unit.fuse(&self.interface_ptr, &adjacent_unit.interface_ptr, adjacent_dual_unit);
    //     // self.serial_module.fuse(&left_child.serial_module, &right_child.serial_module);
    // }
}

impl PrimalModuleImpl for PrimalModuleParallel {
    /// create a primal module given the dual module
    fn new_empty(_solver_initializer: &SolverInitializer, _model_graph: &ModelHyperGraph) -> Self {
        // Self::new_config(
        //     solver_initializer,
        //     &PartitionConfig::new(solver_initializer.vertex_num).info(),
        //     PrimalModuleParallelConfig::default(),
        //     model_graph,
        // )
        panic!("call new_config in PrimalModuleParallel instead");
    }

    /// clear all states; however this method is not necessarily called when load a new decoding problem, so you need to call it yourself
    fn clear(&mut self) {
        self.thread_pool.scope(|_| {
            self.units.par_iter().enumerate().for_each(|(unit_idx, unit_ptr)| {
                let mut unit = unit_ptr.write();
                unit.clear();
            });
        });
    }

    /// load a new decoding problem given dual interface: note that all nodes MUST be defect node
    fn load<D: DualModuleImpl>(&mut self, interface_ptr: &DualModuleInterfacePtr, dual_module: &mut D) {
        panic!("load interface directly into the parallel primal module is forbidden, use `parallel_solve` instead");
    }

    /// analyze the reason why dual module cannot further grow, update primal data structure (alternating tree, temporary matches, etc)
    /// and then tell dual module what to do to resolve these conflicts;
    /// note that this function doesn't necessarily resolve all the conflicts, but can return early if some major change is made.
    /// when implementing this function, it's recommended that you resolve as many conflicts as possible.
    fn resolve(
        &mut self,
        group_max_update_length: GroupMaxUpdateLength,
        interface: &DualModuleInterfacePtr,
        dual_module: &mut impl DualModuleImpl,
    ) {
        panic!("parallel primal module cannot handle global resolve requests, use `parallel_solve` instead");
    }

    fn solve(
        &mut self,
        interface: &DualModuleInterfacePtr,
        syndrome_pattern: Arc<SyndromePattern>,
        dual_module: &mut impl DualModuleImpl,
    ) {
        self.solve_step_callback(interface, syndrome_pattern, dual_module, |_, _, _, _| {})
    }

    fn subgraph(&mut self, interface: &DualModuleInterfacePtr, dual_module: &mut impl DualModuleImpl) -> Subgraph {
        let mut subgraph = vec![];
        for unit_ptr in self.units.clone() {
            let mut unit = unit_ptr.write();
            let local_subgraph = unit.subgraph(interface, dual_module);
            let bias_subgraph: Vec<usize> = local_subgraph.clone().into_iter().map(|x| {dual_module.get_edge_global_index(x, unit.unit_index)}).collect();
            println!("local_subgraph: {local_subgraph:?}");
            println!("bias_subgraph: {bias_subgraph:?}");
            subgraph.extend(bias_subgraph);
        }
        subgraph
    }

    // fn subgraph_range(
    //     &mut self,
    //     interface: &DualModuleInterfacePtr,
    //     dual_module: &mut impl DualModuleImpl,
    // ) -> (Subgraph, WeightRange) {
    //     let subgraph = self.subgraph(interface, dual_module);
    //     let weight_range = WeightRange::new(
    //         interface.sum_dual_variables(),
    //         Rational::from_usize(
    //             interface
    //                 .read_recursive()
    //                 .decoding_graph
    //                 .model_graph
    //                 .initializer
    //                 .get_subgraph_total_weight(&subgraph),
    //         )
    //         .unwrap(),
    //     );
    //     (subgraph, weight_range)
    // }

    /// performance profiler report
    fn generate_profiler_report(&self) -> serde_json::Value {
        json!({})
    }
}

impl PrimalModuleParallelUnit {
    /// fuse two units together, by copying the right child's content into the left child's content and resolve index;
    /// note that this operation doesn't update on the dual module, call [`Self::break_matching_with_mirror`] if needed
    pub fn fuse<DualSerialModule: DualModuleImpl + Send + Sync>(
        &mut self,
        dual_unit_ptr: &mut DualModuleParallelUnitPtr<DualSerialModule>,
        adjacent_unit: &Self,
        adjacent_dual_unit_ptr: &mut DualModuleParallelUnitPtr<DualSerialModule>,
    ) {
        println!("hiasfasfads");
        dual_unit_ptr.fuse(&self.interface_ptr, &adjacent_unit.interface_ptr, adjacent_dual_unit_ptr);

        println!("hiasfdddddddasfads");
        // drop(dual_unit);

        // println!("hiasfasfads");
        // // let mut adjacent_dual_unit = adjacent_dual_unit_ptr.write();
        // adjacent_dual_unit_ptr.fuse(&adjacent_unit.interface_ptr, &self.interface_ptr, dual_unit_ptr);
        // drop(adjacent_dual_unit);
        // self.serial_module.fuse(&left_child.serial_module, &right_child.serial_module);
    }

    // fn adjacent_update<DualSerialModule: DualModuleImpl + Send + Sync>(
    //     &mut self, 
    //     adjacent_dual_unit: &mut DualModuleParallelUnit<DualSerialModule>, 
    //     primal_unit: &Self,
    // ) {
    //     let adjacent_unit_count = self.adjacent_parallel_units.len();
    //     // let adjacent_dual_unit_ptr = parallel_dual_module.get_unit(adjacent_unit.unit_index);
    //     for adjacent_index0 in 0..adjacent_unit_count {
    //         println!("inside adjacent");
    //         // Re-acquire the read lock for each iteration of the loop            
    //         if self.adjacent_parallel_units[adjacent_index0].1 {
    //             continue;
    //         }

    //         let adjacent_unit0_weak = &self.adjacent_parallel_units[adjacent_index0].0;
    //         println!("hihi");

    //         let adjacent_unit0_ptr = adjacent_unit0_weak.upgrade_force();
    //         let adjacent_unit0 = adjacent_unit0_ptr.read_recursive();
    //         println!("hello");

    //         if adjacent_unit0.unit_index == primal_unit.unit_index {
    //             println!("inside if");
    
    //             self.adjacent_parallel_units[adjacent_index0].1 = true;
    //             adjacent_dual_unit.adjacent_parallel_units[adjacent_index0].1 = true;
    
    //             let mut interface_write = self.interface_ptr.write();
    //             interface_write.adjacent_parallel_units[adjacent_index0].1 = true;    
    //             break;
    //         }
    //     }
    // }

    // fn fuse_with_adjacent<DualSerialModule: DualModuleImpl + Send + Sync>(
    //     &mut self, 
    //     dual_unit: &mut DualModuleParallelUnit<DualSerialModule>, 
    //     adjacent_index: usize,
    //     adjacent_dual_unit: &mut DualModuleParallelUnit<DualSerialModule>,
    // ) {

    //     println!("inside fuse with adjacent");
    //     if self.adjacent_parallel_units[adjacent_index].1 {
    //         return;
    //     }

    //     self.adjacent_parallel_units[adjacent_index].1 = true;
    //     dual_unit.adjacent_parallel_units[adjacent_index].1 = true;

    //     // Mark the adjacent unit as fused in the interface
    //     {
    //         let mut primal_unit_interface_write = self.interface_ptr.write();
    //         primal_unit_interface_write.adjacent_parallel_units[adjacent_index].1 = true;
    //     }
        
    //     {
    //         let adjacent_unit_weak = &self.adjacent_parallel_units[adjacent_index].0;
    //         let adjacent_unit_ptr = adjacent_unit_weak.upgrade_force();
    //         let mut adjacent_unit = adjacent_unit_ptr.write();
    
    //         adjacent_unit.adjacent_update(adjacent_dual_unit, self);

    //     }
    // }

    #[allow(clippy::unnecessary_cast)]
    pub fn break_matching_with_mirror(&mut self, dual_module: &mut impl DualModuleImpl) {
        // use `possible_break` to efficiently break those
        // let mut possible_break = vec![];
        // let module = self.write();

        println!("break_matching_with_mirror unit index {}", self.unit_index);
        for temp in self.serial_module.temporary_match.iter() {
            println!("temporary match: vertex index {} to primal cluster {}", temp.0, temp.1.upgrade_force().read().cluster_index);
        }
        for (boundary_vertex_range,(_, _)) in self.partition_info.units[self.unit_index].boundary_vertices.iter() {
            for boundary_vertex_index in boundary_vertex_range.range[0]..boundary_vertex_range.range[1] {
                let cluster_ptr = self.serial_module.temporary_match.get(&boundary_vertex_index);
                match cluster_ptr {
                    Some(cluster_weak) => {
                        let cluster_ptr = cluster_weak.upgrade_force();
                        let cluster = cluster_ptr.write();
                        println!("cluster found with id {} connected to boundary_vertex {}", cluster.cluster_index, boundary_vertex_index);
                        // set all nodes to grow in the cluster
                        for primal_node_ptr in cluster.nodes.iter() {
                            let dual_node_ptr = primal_node_ptr.read_recursive().dual_node_ptr.clone();
                            dual_module.set_grow_rate(&dual_node_ptr, Rational::one());
                        }
                    }, 
                    None => {}
                }

            }
        }
    }
}

impl PrimalModuleParallel {
    pub fn parallel_solve<DualSerialModule: DualModuleImpl + Send + Sync>(
        &mut self,
        syndrome_pattern: Arc<SyndromePattern>,
        parallel_dual_module: &DualModuleParallel<DualSerialModule>,
    ) {
        self.parallel_solve_step_callback(syndrome_pattern, parallel_dual_module, |_, _, _, _| {});
    }

    pub fn parallel_solve_visualizer<DualSerialModule: DualModuleImpl + Send + Sync + MWPSVisualizer>(
        &mut self,
        syndrome_pattern: Arc<SyndromePattern>,
        parallel_dual_module: &DualModuleParallel<DualSerialModule>,
        visualizer: Option<&mut Visualizer>,
    ) {
        if let Some(visualizer) = visualizer {
            self.parallel_solve_step_callback(
                syndrome_pattern,
                parallel_dual_module,
                |interface, dual_module, primal_module, group_max_update_length| {
                    if let Some(group_max_update_length) = group_max_update_length {
                        if cfg!(debug_assertions) {
                            println!("group_max_update_length: {:?}", group_max_update_length);
                        }
                        if group_max_update_length.is_unbounded() {
                            visualizer
                                .snapshot_combined("unbounded grow".to_string(), vec![interface, dual_module, primal_module])
                                .unwrap();
                        } else if let Some(length) = group_max_update_length.get_valid_growth() {
                            visualizer
                                .snapshot_combined(format!("grow {length}"), vec![interface, dual_module, primal_module])
                                .unwrap();
                        } else {
                            let first_conflict = format!("{:?}", group_max_update_length.peek().unwrap());
                            visualizer
                                .snapshot_combined(
                                    format!("resolve {first_conflict}"),
                                    vec![interface, dual_module, primal_module],
                                )
                                .unwrap();
                        };
                    } else {
                        visualizer
                            .snapshot_combined("unit solved".to_string(), vec![interface, dual_module, primal_module])
                            .unwrap();
                    }
                    
                },
            );
            // let last_unit = self.units.last().unwrap().read_recursive();
            // visualizer
            //     .snapshot_combined(
            //         "solved".to_string(),
            //         vec![&last_unit.interface_ptr, parallel_dual_module, self],
            //     )
            //     .unwrap();
        } else {
            self.parallel_solve(syndrome_pattern, parallel_dual_module);
        }
    }

    pub fn parallel_solve_step_callback<DualSerialModule: DualModuleImpl + Send + Sync, F: Send + Sync>(
        &mut self,
        syndrome_pattern: Arc<SyndromePattern>,
        parallel_dual_module: &DualModuleParallel<DualSerialModule>,
        mut callback: F,
    ) where
        F: FnMut(
            &DualModuleInterfacePtr,
            &DualModuleParallelUnit<DualSerialModule>,
            &PrimalModuleSerial,
            Option<&GroupMaxUpdateLength>,
        ),
    {
        // let thread_pool = Arc::clone(&self.thread_pool);
        for unit_index in 0..self.partition_info.units.len() {
            let unit_ptr = self.units[unit_index].clone();
            unit_ptr.individual_solve::<DualSerialModule, F>(
                self, 
                PartitionedSyndromePattern::new(&syndrome_pattern), 
                parallel_dual_module, 
                &mut Some(&mut callback),
            );
        }

        for unit_index in 0..self.partition_info.units.len() - 1 {
            let unit_ptr = self.units[unit_index].clone();
            unit_ptr.fuse_and_solve::<DualSerialModule, F>(
                self, 
                PartitionedSyndromePattern::new(&syndrome_pattern), 
                parallel_dual_module, 
                &mut Some(&mut callback),
            );
        }
    }
}

impl MWPSVisualizer for PrimalModuleParallel {
    fn snapshot(&self, abbrev: bool) -> serde_json::Value {
        // do the sanity check first before taking snapshot
        // self.sanity_check().unwrap();
        let mut value = json!({});
        for unit_ptr in self.units.iter() {
            let unit = unit_ptr.read_recursive();
            // if !unit.is_active {
            //     continue;
            // } // do not visualize inactive units
            let value_2 = unit.snapshot(abbrev);
            snapshot_combine_values(&mut value, value_2, abbrev);
        }
        value
    }
}

impl MWPSVisualizer for PrimalModuleParallelUnit {
    fn snapshot(&self, abbrev: bool) -> serde_json::Value {
        self.serial_module.snapshot(abbrev)
    }
}

impl PrimalModuleImpl for PrimalModuleParallelUnit {
    /// create a primal module given the dual module
    fn new_empty(_solver_initializer: &SolverInitializer, model_graph: &ModelHyperGraph) -> Self {
        panic!("creating parallel unit directly from initializer is forbidden, use `PrimalModuleParallel::new` instead");
    }

    /// clear all states; however this method is not necessarily called when load a new decoding problem, so you need to call it yourself
    fn clear(&mut self) {
        self.serial_module.clear();
        self.interface_ptr.clear();
    }

    /// load a new decoding problem given dual interface: note that all nodes MUST be defect node
    fn load<D: DualModuleImpl>(&mut self, interface_ptr: &DualModuleInterfacePtr, dual_module: &mut D) {
        self.serial_module.load(interface_ptr, dual_module);
    }

    /// analyze the reason why dual module cannot further grow, update primal data structure (alternating tree, temporary matches, etc)
    /// and then tell dual module what to do to resolve these conflicts;
    /// note that this function doesn't necessarily resolve all the conflicts, but can return early if some major change is made.
    /// when implementing this function, it's recommended that you resolve as many conflicts as possible.
    fn resolve(
        &mut self,
        group_max_update_length: GroupMaxUpdateLength,
        interface: &DualModuleInterfacePtr,
        dual_module: &mut impl DualModuleImpl,
    ) {
        self.serial_module.resolve(group_max_update_length, interface, dual_module);

    }

    fn subgraph(&mut self, interface: &DualModuleInterfacePtr, dual_module: &mut impl DualModuleImpl) -> Subgraph {
        self.serial_module.subgraph(interface, dual_module)
    }

    fn subgraph_range(
        &mut self,
        interface: &DualModuleInterfacePtr,
        dual_module: &mut impl DualModuleImpl,
    ) -> (Subgraph, WeightRange) {
        let subgraph = self.subgraph(interface, dual_module);
        let weight_range = WeightRange::new(
            interface.sum_dual_variables(),
            Rational::from_usize(
                interface
                    .read_recursive()
                    .decoding_graph
                    .model_graph
                    .initializer
                    .get_subgraph_total_weight(&subgraph),
            )
            .unwrap(),
        );
        (subgraph, weight_range)
    }

    /// performance profiler report
    fn generate_profiler_report(&self) -> serde_json::Value {
        json!({})
    }
}



#[cfg(test)]
pub mod tests {
    use super::super::example_codes::*;
    use super::super::primal_module::*;
    use super::super::primal_module_serial::*;
    use crate::decoding_hypergraph::*;
    use super::*;
    use crate::num_traits::FromPrimitive;

    use crate::plugin_single_hair::PluginSingleHair;
    use crate::plugin_union_find::PluginUnionFind;
    use crate::plugin::PluginVec;
    use crate::dual_module_serial::*;
    
    #[allow(clippy::too_many_arguments)]
    pub fn primal_module_parallel_basic_standard_syndrome_optional_viz(
        _code: impl ExampleCode,
        defect_vertices: Vec<VertexIndex>,
        final_dual: Weight,
        plugins: PluginVec,
        growing_strategy: GrowingStrategy,
        mut dual_module: DualModuleParallel<DualModuleSerial>,
        mut primal_module: PrimalModuleParallel,
        model_graph: Arc<crate::model_hypergraph::ModelHyperGraph>,
        mut visualizer: Option<Visualizer>,
    ) -> (
        DualModuleInterfacePtr,
        PrimalModuleParallel,
        impl DualModuleImpl + MWPSVisualizer,
    ) {
        // try to work on a simple syndrome
        let decoding_graph = DecodingHyperGraph::new_defects(model_graph, defect_vertices.clone());
        let interface_ptr = DualModuleInterfacePtr::new(decoding_graph.model_graph.clone());
        primal_module.parallel_solve_visualizer(
            decoding_graph.syndrome_pattern.clone(),
            &mut dual_module,
            visualizer.as_mut(),
        );


        let (subgraph, weight_range) = primal_module.subgraph_range(&interface_ptr, &mut dual_module);
        if let Some(visualizer) = visualizer.as_mut() {
            visualizer
                .snapshot_combined(
                    "subgraph".to_string(),
                    vec![&interface_ptr, &dual_module, &subgraph, &weight_range],
                )
                .unwrap();
        }
        // assert!(
        //     decoding_graph
        //         .model_graph
        //         .matches_subgraph_syndrome(&subgraph, &defect_vertices),
        //     "the result subgraph is invalid"
        // );
        // assert_eq!(
        //     Rational::from_usize(final_dual).unwrap(),
        //     weight_range.upper,
        //     "unmatched sum dual variables"
        // );
        // assert_eq!(
        //     Rational::from_usize(final_dual).unwrap(),
        //     weight_range.lower,
        //     "unexpected final dual variable sum"
        // );
        (interface_ptr, primal_module, dual_module)
    }

    pub fn primal_module_parallel_basic_standard_syndrome(
        code: impl ExampleCode,
        visualize_filename: String,
        defect_vertices: Vec<VertexIndex>,
        final_dual: Weight,
        plugins: PluginVec,
        growing_strategy: GrowingStrategy,
    ) -> (
        DualModuleInterfacePtr,
        PrimalModuleParallel,
        impl DualModuleImpl + MWPSVisualizer,
    ){
        println!("{defect_vertices:?}");
        let visualizer = {
            let visualizer = Visualizer::new(
                Some(visualize_data_folder() + visualize_filename.as_str()),
                code.get_positions(),
                true,
            )
            .unwrap();
            print_visualize_link(visualize_filename.clone());
            visualizer
        };

        // create dual module
        let model_graph = code.get_model_graph();
        let initializer = &model_graph.initializer;
        let mut partition_config = PartitionConfig::new(initializer.vertex_num);
        partition_config.partitions = vec![
            VertexRange::new(0, 18),   // unit 0
            VertexRange::new(24, 42), // unit 1
        ];
        partition_config.fusions = vec![
                    (0, 1), // unit 2, by fusing 0 and 1
                ];
        let a = partition_config.dag_partition_units.add_node(());
        let b = partition_config.dag_partition_units.add_node(());
        partition_config.dag_partition_units.add_edge(a, b, false);
        
        let partition_info = partition_config.info();
        let dual_module: DualModuleParallel<DualModuleSerial> =
            DualModuleParallel::new_config(&initializer, &partition_info, DualModuleParallelConfig::default());

        // create primal module
        let model_graph = code.get_model_graph();
        let primal_config = PrimalModuleParallelConfig {..Default::default()};
        let primal_module = PrimalModuleParallel::new_config::<DualModuleSerial>(&model_graph.initializer, &partition_info, primal_config.clone(), &dual_module);

        // primal_module.growing_strategy = growing_strategy;
        // primal_module.plugins = Arc::new(plugins);
        // primal_module.config = serde_json::from_value(json!({"timeout":1})).unwrap();

        primal_module_parallel_basic_standard_syndrome_optional_viz(
            code,
            defect_vertices,
            final_dual,
            plugins,
            growing_strategy,
            dual_module,
            primal_module,
            model_graph,
            Some(visualizer),
        )
    }

    /// test a simple case
    #[test]
    fn primal_module_parallel_tentative_test_1() {
        // RUST_BACKTRACE=1 cargo test primal_module_parallel_tentative_test_1 -- --nocapture
        let weight = 1; // do not change, the data is hard-coded
        // let pxy = 0.0602828812732227;
        let code = CodeCapacityPlanarCode::new(7, 0.1, weight);
        let defect_vertices = vec![9, 29];

        let visualize_filename = "dual_module_parallel_tentative_test_3.json".to_string();
        primal_module_parallel_basic_standard_syndrome(
            code,
            visualize_filename,
            defect_vertices,
            4,
            vec![],
            GrowingStrategy::SingleCluster,
        );
    }

    #[test]
    fn dual_module_parallel_tentative_test_1() {
        // cargo test dual_module_parallel_tentative_test_1 -- --nocapture
        let visualize_filename = "dual_module_parallel_tentative_test_1.json".to_string();
        let weight = 600; // do not change, the data is hard-coded
        // let pxy = 0.0602828812732227;
        let code = CodeCapacityPlanarCode::new(7, 0.1, weight);
        let mut visualizer = Visualizer::new(
            Some(visualize_data_folder() + visualize_filename.as_str()),
            code.get_positions(),
            true,
        )
        .unwrap();
        print_visualize_link(visualize_filename);
        visualizer.snapshot("code".to_string(), &code).unwrap();

        // create dual module
        let model_graph = code.get_model_graph();
        let initializer = &model_graph.initializer;
        let mut partition_config = PartitionConfig::new(initializer.vertex_num);
        partition_config.partitions = vec![
            VertexRange::new(0, 18),   // unit 0
            VertexRange::new(24, 42), // unit 1
        ];
        partition_config.fusions = vec![
                    (0, 1), // unit 2, by fusing 0 and 1
                ];
        let a = partition_config.dag_partition_units.add_node(());
        let b = partition_config.dag_partition_units.add_node(());
        partition_config.dag_partition_units.add_edge(a, b, false);

        let partition_info = partition_config.info();

        // create dual module
        let mut dual_module: DualModuleParallel<DualModuleSerial> =
            DualModuleParallel::new_config(&initializer, &partition_info, DualModuleParallelConfig::default());
        
        // try to work on a simple syndrome
        let decoding_graph = DecodingHyperGraph::new_defects(model_graph, vec![3, 29, 30]);
        let interface_ptr = DualModuleInterfacePtr::new_load(decoding_graph, &mut dual_module);
        
        // println!("interface_ptr json: {}", interface_ptr.snapshot(false));
        // println!("dual_module json: {}", dual_module.snapshot(false));

        visualizer
            .snapshot_combined("syndrome".to_string(), vec![&interface_ptr, &dual_module])
            .unwrap();

        // grow them each by half
        let dual_node_3_ptr = interface_ptr.read_recursive().nodes[0].clone();
        let dual_node_12_ptr = interface_ptr.read_recursive().nodes[1].clone();
        let dual_node_30_ptr = interface_ptr.read_recursive().nodes[2].clone();
        dual_module.grow_dual_node(&dual_node_3_ptr, Rational::from_usize(weight / 2).unwrap());
        dual_module.grow_dual_node(&dual_node_12_ptr, Rational::from_usize(weight / 2).unwrap());
        dual_module.grow_dual_node(&dual_node_30_ptr, Rational::from_usize(weight / 2).unwrap());
        visualizer
            .snapshot_combined("grow".to_string(), vec![&interface_ptr, &dual_module])
            .unwrap();

        // cluster becomes solved
        dual_module.grow_dual_node(&dual_node_3_ptr, Rational::from_usize(weight / 2).unwrap());
        dual_module.grow_dual_node(&dual_node_12_ptr, Rational::from_usize(weight / 2).unwrap());
        dual_module.grow_dual_node(&dual_node_30_ptr, Rational::from_usize(weight / 2).unwrap());

        visualizer
            .snapshot_combined("solved".to_string(), vec![&interface_ptr, &dual_module])
            .unwrap();

        // the result subgraph
        let subgraph = vec![15, 20, 27];
        visualizer
            .snapshot_combined("subgraph".to_string(), vec![&interface_ptr, &dual_module, &subgraph])
            .unwrap();
    }

     // pub fn primal_module_parallel_basic_standard_syndrome(
    //     code: impl ExampleCode,
    //     visualize_filename: String,
    //     defect_vertices: Vec<VertexIndex>,
    //     final_dual: Weight,
    //     plugins: PluginVec,
    //     growing_strategy: GrowingStrategy,
    // ) -> (
    //     DualModuleInterfacePtr,
    //     PrimalModuleParallel,
    //     impl DualModuleImpl + MWPSVisualizer,
    // ) {
    //     println!("{defect_vertices:?}");
    //     let visualizer = {
    //         let visualizer = Visualizer::new(
    //             Some(visualize_data_folder() + visualize_filename.as_str()),
    //             code.get_positions(),
    //             true,
    //         )
    //         .unwrap();
    //         print_visualize_link(visualize_filename.clone());
    //         visualizer
    //     };

    //     // create dual module
    //     let model_graph = code.get_model_graph();
    //     let initializer = &model_graph.initializer;
    //     let mut partition_config = PartitionConfig::new(initializer.vertex_num);
    //     partition_config.partitions = vec![
    //         VertexRange::new(0, 18),   // unit 0
    //         VertexRange::new(24, 42), // unit 1
    //     ];
    //     partition_config.fusions = vec![
    //                 (0, 1), // unit 2, by fusing 0 and 1
    //             ];
    //     let partition_info = partition_config.info();
    //     let mut dual_module: DualModuleParallel<DualModuleSerial> =
    //         DualModuleParallel::new_config(&initializer, &partition_info, DualModuleParallelConfig::default());

    //     // create primal module
    //     let primal_config = PrimalModuleParallelConfig {..Default::default()};
    //     let mut primal_module = PrimalModuleParallel::new_config(&model_graph.initializer, &partition_info, primal_config.clone(), &model_graph);

    //     // primal_module.growing_strategy = growing_strategy;
    //     // primal_module.plugins = Arc::new(plugins);
    //     // primal_module.config = serde_json::from_value(json!({"timeout":1})).unwrap();
    //     // try to work on a simple syndrome
    //     let decoding_graph = DecodingHyperGraph::new_defects(model_graph, defect_vertices.clone());
    //     let interface_ptr = DualModuleInterfacePtr::new(decoding_graph.model_graph.clone());
    //     primal_module.parallel_solve_visualizer(
    //         decoding_graph.syndrome_pattern.clone(),
    //         &mut dual_module,
    //         Some(visualizer).as_mut(),
    //     );


    //     let (subgraph, weight_range) = primal_module.subgraph_range(&interface_ptr, &mut dual_module);
    //     // if let Some(visualizer) = Some(visualizer).as_mut() {
    //     //     visualizer
    //     //         .snapshot_combined(
    //     //             "subgraph".to_string(),
    //     //             vec![&interface_ptr, &dual_module, &subgraph, &weight_range],
    //     //         )
    //     //         .unwrap();
    //     // }
    //     // assert!(
    //     //     decoding_graph
    //     //         .model_graph
    //     //         .matches_subgraph_syndrome(&subgraph, &defect_vertices),
    //     //     "the result subgraph is invalid"
    //     // );
    //     // assert_eq!(
    //     //     Rational::from_usize(final_dual).unwrap(),
    //     //     weight_range.upper,
    //     //     "unmatched sum dual variables"
    //     // );
    //     // assert_eq!(
    //     //     Rational::from_usize(final_dual).unwrap(),
    //     //     weight_range.lower,
    //     //     "unexpected final dual variable sum"
    //     // );
    //     (interface_ptr, primal_module, dual_module)
    // }

}